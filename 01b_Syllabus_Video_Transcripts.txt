Video Library
Access our collection of educational videos covering all essential topics for the Summer Residency Program. Videos are organized by week to help you understand when each session takes place.




Onboarding Call Recording
Program Launch
Live kick-off call and program orientation session: https://www.youtube.com/watch?v=CFpksALEx4w
Summer Residency Intro Summary
Hi guys, we were originally going to


post the videos that we recorded of the


introductory calls um that we made


yesterday. And as I was going through


them, I realized there's um it's a lot


of stuff to watch for minimal


information. So, it's it's probably more


efficient if I re-record and just go


over the main uh the most important


voice here. So


obviously um the first is


congratulations and welcome to the


summer residency.


Uh the second is here is your one-stop


shop um center for all info about the


program. So summer residency.replet.app.


Um here you can get an overview


timeline, you can see the video


recordings um and get all the info that


you need. So, this is the beginning of


four weeks of learning about the


Superior Agents um framework, the GitHub


repo, how to interact with it, how to


edit the prompts and so on, and how


eventually to make your own agent app


that hopefully will be ready to demo and


ready even to raise funds on or to


become a small business.


There is a $4,000 total prize pool uh


with 40 prize slots available.


We are


aiming to have a program that is kind of


halfway between a hackathon and uh an


internship essentially. And obviously


with the the career benefits of both you


you should get a a for freeo that is


yours alone that you can show off. you


should get to do your demo day, connect


with VCs, connect with other people in


the sector, connect with employers, and


um yeah, hopefully set yourself on the


way to a career in in AI or or in agents


in particular.


So, this is obviously a four-week


course. We are starting now in week one


with the kickoff call. Um hopefully


what you're going to be doing this week


is just watching through the initial


videos, installing and setting up your


first agents locally and also um which


is not included in this in this form is


a form that we are going to send you


which is about your initial ideas about


what kind of agent you want to build. Um


do you want to do a trading agent? Do


you want to do um something else?


So we have some ideas for agents in in


the group but um it's it's really very


much up to you and what I would say is


that


particularly in the at the demo day


after the four weeks when we judge who


who has the best projects who who's


winning the prizes and so on. Um


essentially what we're interested in is


the wow factor. So that might be


technological wow like oh this is


integrated with Sakana's Darwin Godell


machine and and isn't this amazing and


the tech is so complex but it could also


be oh the these guys have a great


business plan um and we're we're really


impressed with their go to market or it


could be the prompt engine you know all


that is changed in this one app is


prompt engineering but the prompt


engineering has managed to 10x the


performance so anything that that kind


of really stands out like that one other


thing that should be mentioned here is


that teamwork is allowed. It's it's


fine. It's encouraged. If you have


potential team members who are not in


the program, um you can absolutely bring


them in. Just you know, let us know um


that you're that you're going to be


working on a team and you know sharing


the prizes. Um, on the other hand, if


you want to find team members and


potentially even co-founders, feel free


to post in the Telegram group and um put


your request out there. Uh, it's it's a


great way to to connect and to to boost


your performance by working together.


But equally, if you if you if you prefer


to work alone, then that is also fine


and definitely go ahead with that.


So, week two is going to be the deep


dive and the ideation. So obviously


you're going to be filling out your


ideation forms end of this week and then


going into more depth with them uh next


week. So with the goal of that is by uh


the second Friday to be posting your


project concept and and sharing it with


the group. On the way to that you're


going to be learning about different um


different agent integration. So this


would be things like MCP like um multi-


aent orchestration and and so on.


Week three, um, we're going to be going


into more depth in the prototyping. Uh,


we're going to be doing office hours and


then there's a checkpoint submission as


well. So, in that case, as in throughout


the throughout the program, if you're


having issues, if you're stuck, if


you've got bugs, um, please post in


either the Telegram or the Discord


because there are going to be people


there available to help you. In


particular, we do have tech support guys


in both. So if you if you want to tag me


or Emir or um sw human who is our tech


support guy um yeah we can we can


definitely help out.


So week four is the final bug fixes, the


final little improvements in the


documentation and then the demo video


and then the demo day. So yeah, it's


pretty simple.


uh we have the video library here which


you you can obviously start watching


immediately and um other resources so


the documentation and the GitHub and so


on and then then FAQs.


So


what I do also want to go over on this


is a couple of questions that came up uh


during the during the sessions. So um


first of all what is Azure Labs? So,


Azure Labs is the company that


essentially owns the IP that underlies


superior agents which uh was created by


Kip as an implementation of this


technology in the the trading domain.


Second question, um


do I get free APIs? Uh you can but not


from us unfortunately. The managing API


usage among a whole cohort of people is


insanely complex. So uh what we're


saying is that we're not going to be pro


providing the APIs but what you can try


is for example signing up to Google


cloud platform because they usually if


you sign up they they will give you some


free credits and that means you can use


Gemini you can host there and so on. You


can also try open router which has some


free API access things like coin gecko


they have a free tier and and so on and


so forth. So it it is pretty much


possible to do um


free or very cheap. And the the other


one would be um


um Google Collab, which is good. Um so


the if you're using that, they will I


think give you a give you a a high


quality GPU for for free for sort of six


or eight hours. Um if you want to


experiment with that. Um next question.


Is there a specified tech stack? um not


outside of the agent framework in the


GitHub. Um whatever you want to use with


that, whether it's Langraph, whether


it's um solidity code, whether it's um


you know APIs from different apps like


maybe Robin Hood for trading trading


stocks, anything is fine. No worries.


It's it's all good. Um


what else? Uh are we going to do some


workshops?


Yeah. Um, I would very much like to do


that particularly in week four because


I'd like to do a deployment workshop in


in week four about how to get your agent


up and running on on a cloud server. Uh,


it it's kind of hard to do workshops if


you're if you're focusing on the local


because a lot of the time there's


there's going to be differences between


Linux and Mac and Windows. But I think


what we can definitely do is kind of


just do a quick run through for people


who who aren't used to the DevOps side


of things just to say okay here's how


you would deploy to GCP to Contabo you


want to deploy via Versell or Fly.io


these are these are all the options that


you have and and walk through and that


that is much less affected by your own


OS. So it's um yeah it's it's easier to


do in a workshop format.


Um


those were the main questions I think.


Uh question about languages I think came


up. So yeah, whatever languages you want


to write in is is 100% fine. Um


and that is


the main points I think that is that is


the the major questions that uh


that came up.


So I would just say welcome to the


program. Thank you for joining and I


can't wait to see what you're going to


build. Bye.


--------------------------
Welcome Video
Week 1 (June 9-13)
Welcome to the Superior Agents Summer Residency Program: https://www.youtube.com/watch?v=z3U1rp-hB58
Welcome to the Superior Agents Summer Residency
Hi everyone and welcome to the Superior


Agents summer residency. I'm excited


you're here because what we're going


into over the next four weeks is not


going to be your average AI internship.


So most of the AI agents out there are


basically kind of boring. Either the too


predictable to be interesting or too


unpredictable to be useful. And we want


to move past that with superior agents.


Most agents are like goldfish basically.


They they swim in circles. They know


their patterns and then they're


constantly just waiting for the next


prompt to respond to it. And ours aren't


like that. Superior agents don't just


pretend to be intelligent. They actually


fight to survive. They learn. They


adapt. They replicate. And sometimes


they can even outwit their creators. And


in this case, that means all of you. So


over the next four weeks, you're going


to go from zero to creating your own


autonomous self-evolving agents using


our platform. And that means you're


going to be building agents that measure


their own success, that can survive in


the wild without human assistance, that


improve by learning from real world


feedback from their empirical


experiences, and evolve without


handholding after the first initial


setup.


So what we're going to do in in this


program is start out by helping you


whether you are a complete beginner,


you've never written a line of code, or


whether you already know quite a lot


about AI and agents. We're going to


start out by helping you uh launch your


first superior agent via tutorials,


AMAs, feedback checkpoints, and and also


just community community advice.


and then go from there to building your


own um you know internet ready product


that can potentially be used to you know


to raise funds or to to gain revenue. So


week one is going to be the the


onboarding and the initial agent setup.


So hopefully you've had a chance to


check out the Discord, check out the um


check out the GitHub as well. And uh


this week is going to be all about


getting your first agents up and


running. Next week, we're going to be


going into a bit more of the the


in-depth stuff. So, the integrations,


possible integrations with say MCP or


Google's agent to agent framework.


Then, in week three, it's going to be


all about your projects. So, we're going


to be checking in uh seeing how you're


progressing, coming up with your own


your own concepts and your your own


version of the the superior agent


design. And then week four is going to


be the demo day. So that is when you get


to show off your creations to obviously


to us, but also to our partners, to the


judges, and to the community at large.


So yeah, there are going to be prizes


for that. There's going to be obviously


money, swag, and uh I have the the


shirts in a box behind me. I can confirm


they're very cool. and obviously the the


kudos for having done it, but also


potentially a job in the new post AAI


employment world. So yeah, it's time to


get going. Um, get on the Discord, get


on the GitHub if you haven't yet, start


checking out the docs and start building


because the age of obedience AI is over.


We want to build agents that earn the


right to run. So, welcome to the future


and welcome to Superior Agents.



----------------------------
Why Build an Agent?
Week 1 (June 9-13)
Understanding the fundamentals and motivation behind building Al agents: https://www.youtube.com/watch?v=e_EkE4el-cw
Why build an agent
Hi everybody. Welcome to the Superior


Agent Summer Residency and


congratulations for making it this far.


Given how many people applied is a real


achievement. So, I just wanted to give


you a few tips, hints, pointers


about what you should be aiming for over


the course of these four weeks because


hopefully each and every one of you is


going to come out of this with a brand


new marketable project based around the


superior agents framework that you


should by this point already have


checked out on GitHub and be starting to


familiarize yourself with. So obviously


on the on the the GitHub you have a


choice between making a trading agent


and a social media agent and there's


also a secret third type of agent that


you may or may not have discovered yet.


But we don't want you to limit yourself


to those things. Obviously, if you're


super passionate about trading and you


want to make yourself uh say a stock


trading agent instead of a crypto


trading agent or you want to trade on


Saul or you want to make an accessory


that will help the agents for example


find correct contract addresses and not


get scammed by honeypot tokens like some


of ours were then those are all great


projects. Likewise, our social media


agents could do with a bit of


improvement. So, if you want to work on


that, I will be extremely grateful


honestly. But if you want to do


something totally different, that is


also open to you. So if you want to make


a gaming agent, for example, one that's


going to get ever better at playing Doom


or playing Minecraft or whatever, that


is absolutely open to you. Or maybe you


want to make a vibe coding agent, one


that will actually code games for users


to play and respond based on how the


users approve or disapprove of these


choices. Or you could do something


totally different. You could scan the


internet for interesting news and have


the agent turn it into a podcast. You


could scan the internet for interesting


podcasts and have the agent turn them


into mini bucks. You can really do


whatever tickles your fancy as long as


you give your agent a goal and a goal


that can be measured but not completely


controlled by the agent. So a goal that


it can influence but not cheat. So that


is why obviously um the amount of money


in its wallet that's a great goal. the


number of social media followers it has


also a great goal but there are plenty


of others and I'm sure that you're going


to find way more than we have thought of


over the next four weeks so best of luck




--------------------------
Intro to Al Agent Landscape
Week 1 (June 9-13)
Overview of the current Al agent ecosystem and Technologies:https://www.youtube.com/watch?v=QYT4ZaUzdd0
Intro to AI Agents
Hi everyone, welcome to the very first


tutorial of our spirit agent summer


residency program.


Over the next couple of minutes, you


will get a tour of the AI leg agent


landscape. Hopefully enough to take you


from an absolute beginner to an excited


innovator.


By the end, you will understand core


concepts like autonomy versus


automation, simple agent architectures,


and learning paradigms.


We hope that this foundation will set


you to build up and launch your own


spirit agents for our summer residency


program where you can win prizes for


demonstrating real world survival and


evolution in your agents. Without


further ado, let's dive in.


First, let's construct automation with


autonomy.


Automation follows fixed rules. Think a


basic email filter that flags anything


with free money. Autonomy goes even


further than this. It builds and updates


an internal model of its environments,


refine its logic, and makes decisions


not explicitly programmed. So you can


imagine an email agent that learns from


marking of your spam over time, adapting


to its patterns of its own. That's


autonomy. It's crucial for agents that


must survive and evolve in dynamic real


world settings without a human


babysitter.


Now let's consider how agents are built


with simple agent architectures. First


is reactive agents. They're super fast.


They map inputs directly to outputs but


they can plan ahead. It's direct


stimulus with direct action but no


memory is involved.


Next is deliver to agents. They build an


internal world model plan can be slower.


So it's model based planning. its


internal world view.


The sweet spot is hybrid agents which


layer a quick reactive components with a


deeper learning module. This lets agents


respond instantly to new events and


deliberately on strategy much like you


might instantly dodge falling objects


and decides where you were to move for


safety.


So overall, hybrid agents combine


reactive speed with deliberative depth.


Next, I'd like to talk a little bit


about learning paradigms as well


to give agents intelligence.


There's various different learning


paradigms that are applied. Supervised


learning records labeled data. So, this


is almost like feeding a model thousands


of cats and dog images and unsupervised


learning finds hidden patterns and raw


data clustering similar images without


labels.


Self-supervised learning blends both of


these together. So it has teaching


models to predict the parts of the data


from other parts. Understanding these


paradigms will really help you to choose


how an agent and understand acquires


knowledge whether if it's classifying


contents, finding clusters or


bootstrapping from raw inputs as well.


So overall supervised learning learns


from label examples, cats versus dogs.


Unsupervised learning discovers patterns


and unlabelled data. Self and


semi-supervised learning mix of both


leverages structure and data.


Now I'd like to talk a little bit about


deep reinforcement learning and its


basics.


So I will give an example in here that I


would like you to understand.


Reinforcement learning is central to


many autonomous agents.


An re reinforcement learning agent lives


in environment. It observes a state,


acts, receives the rewards and moves to


a new state. It's objective. It's to


maximize total rewards over time. Key


challenge is to exploration and


exploitation tradeoff. Should the agent


try something new, explore or repeat a


known winning action, exploit


reinforcement learning gives agents a


framework for self-improvements through


trial and error, very much like


evolution, making a powerful tool,


adaptive behaviors.


So if you were to look essentially at an


interaction loop, agent observes a state


S, takes action A, gets reward R and


reaches a new state S. The goal again to


maximize cumulative reward over time.


And I would say that the explore versus


exploits, the balance trying to new


actions versus using the good ones is a


very um ongoing literature that's been


in this ecosystem.


The next one is why autonomy matters. So


why do we actually even care about


autonomy? And I'm assuming you will ask


this yourself because we will be


mentioning this throughout the program


over and over. Well, first scalability.


The truly autonomous agents actually


reduce the need for constant human


oversight. The second robustness.


Autonomous agents can handle unexpected


events. Even if they counter something


new, they can adapt instead of failing.


So the third come point comes the


continuous improvement using


evolutionary loops or self-arning


mechanisms. Agents can self-correct and


get smarter with each interaction. In


essence, autonomy is key to move from


narrow systems to resilient


self-optimizing AI. Now let's talk about


evolution of AI. Let's zoom out for a


bit and see how we actually got here. In


the early days of NLP, we relied many of


the humans relied on rigid rules, basic


stats and afterwards the deep learning


era introduced transformers, the models


that understood context at scale


and to many of our lives consumers and


even to developers chatbt and LLM


brought convers conversational AI into


the mainstream


enabling natural dialogues with minimal


prompting. So now we're actually


entering the AI agent phase. We're


talking about chaining large linkage


model calls, hooking agents to memory


stores, planners, and external tools.


This progression moved us from static


text generation to dynamic goal-driven


systems.


Now I believe it's a time to introduce


spir agents, our evolutionary AI


architecture and framework. It's


inspired by dervilian intelligence and


as it helps agents to be evaluated on


survival metrics, persistence,


replication and utility


and agents are not just judged by human


ratings as well. It's like I mentioned


it's all by surv uh survival metrics.


The cycle has essentially four steps.


Initialization where agents boot with


initial settings. You can pick your um


own financial model. Self-evaluation


using ungameable success criteria.


replication where strong agents spawn


offspring to save critical data and


continuous adaptation. Real world


feedback drives evolution. We believe


that this loop truly creates a


self-improving AI that thrives in


dynamic environments.


So again to wrap up, we looked briefly


at the AI l agent landscape from simple


automation scripts to autonomous


evolving agents.


We believe that we gave you some of the


high level architectures, learning


paradigms and why autonomy matters. So


now we hope that you can take this


information and explore this area a


little bit more and


within the next couple of sessions we


will be diving into multi- aent


orchestration a lot more in detail to


understand how to compose a team of


agents and later on we will be also


looking into model contest protocol


basics on how to connect agents to real


world data and series. So, we hope that


with all of these skills that you


combine, you will be ready to launch


your own spirit agents use case and


compete for prizes at the end of our


program.


Once again, thank you for your


attention. Um, you can scan this car


code to access to our docs and you can


find our notion guide and discord


channel um as well with all of the


resources that you have. Don't hesitate


to any of the questions in our discord


um or during our office hours that we


will be hosting. The goal is to make


this summer residency program as


engaging as possible for all of you and


give you a chance to learn about this


landscape in just about four weeks time.


Thank you.



-----------------------
Setting Up Your First Agent
Week 2 (June 16-20)
Step-by-step guide to configuring your Superior Agents Instance:https://www.youtube.com/watch?v=IGIsw5kthq4
Setting up Your First Agent
Hi everybody and welcome to um a very


important lesson in the whole superior


agent summer residency program which is


how to actually create your own copy of


the superior agents code and edit it


locally and then re-upload to to your


own GitHub. And this is really important


because um not only because it's it's


the whole point of the course, but


because on the demo day when uh when we


are awarding prizes, it's going to be


your fork of the superior agents repo


that we we judge uh we judge the


competition on. So you're going to want


to start obviously by creating a new


fork, which is just sort of your own


personal version of this code.


Um,


I am doing this now. So, I'm copying


this to my my own GitHub. Uh,


so I'm going to call it Gen Superior


Agents and create my own personal


version of this now. And you can see


this is the the exact same code, the


exact same everything is just in in my


own account under me. So now if I want


to edit it, I want to get this running


locally. So how I am going to do that?


I'm going to go to I'm going to navigate


to where I want to put it which in my


case is the desktop. I'm going to open


this in a terminal


which uh I am using


um I'm using Abuntu uh as my OS here. So


if if you're on Mac or you're on


Windows, it'll probably look slightly


different, but um it's not that


different.


So the command that I'm going to use,


and again, it's it's going to be very


much like depending on whatever system


you're using, is get clone followed by


the um the URL, which I just copied from


this this code button here. If you don't


have git installed, you might need to


install that, but there are there's a


million instructions on how to do that


online. So, it's you can easily find


something that is adapted to your own


system. So, I am copying this and now


everything has been copied into my


desktop here. So, I can go into the


folder and and see everything that I


need to actually to run this. And I


would like to run this. I mean, I I


could actually just run this out of the


terminal that I'm in now. I I could, you


know, open the folder there and and run


all of the commands because the commands


are actually quite easy now. We've we've


deliberately sort of simplified all of


this down.


So, you can see here if we go to the


quick start uh the quick start


instructions,


very few instructions to to actually get


this thing going.


But if you are going to want to edit


your code,


uh you are


going to probably want um a development


environment that that gives you a bit


more ease of dealing with this. So right


here I'm using um combination of VS code


and cursor which is uh an AI assisted


development environment. No obligation


to use this. I like cursor just cuz I'm


familiar with it, but there are others.


There's wind surf and a whole bunch of


others that you can try out and see see


which one you prefer. So, I'm going to


go to my folder superior agents. And


then I'm going to open this.


And what you should see is it's going to


load up all of my my files and and


folders and my directory structure. Here


I've got my AI panel here where I can I


can ask the AI questions and vibe code.


Um I am using Gemini with this. Um so I


I got my own API key from Gemini because


I I quite like Gemini and I I added this


to the environment to tell it which


model to use. If you're using the free


version, um it doesn't supply every


possible model. So, you're going to have


to live with whatever they choose to


give you. But, um, again, it's uh it's


it's perfectly decent, honestly, the


free version.


Um, so I'm going to open a terminal at


the bottom of the page so that I can I


can interact with with the code. But the


first thing that I need to do per the


per the instructions here is just to


check that I have Docker installed. And


what Docker does is it spares the user


from having to do a whole bunch of


complicated setup tasks. So the reason


this is so simple and and so easy to do


whether you're in Mac, Windows or Linux


is because everything is in Docker and


Docker is going to handle most of it for


me. So I just need to um paste this in


and check that I already have Docker,


which I do. If you don't have it, it's


very easy to install. the the


installation is going to be different


depending on on what system you're


running on, but it's it's easy to do.


And uh


I I have up-to-date versions, but if if


you have an old version, you might want


to update your version before you start


this.


Okay, so I've done that. Now I need to


add in the API keys that are going to


give me access to um OpenAI and also to


my wallet if I'm if I'm making a a


trading agent.


And this is in a file called


end.quickstart


which will be in a folder that is called


examples. So I can actually find it


here.


And this is


information that you don't necessarily


want to share. So I'm I'm sharing the


keys here because obviously it's uh


I I can't do anything else. But um you


want to absolutely keep these private.


So, I need my OpenAI


API key, which I I just pasted in, and a


wallet address and a private key for the


wallet. So, this I I just procedurally


generated a million keys, and I'm I'm


just using one as an example here. So,


I'm going to um paste in my address


here, and then


my finally my key here.


Okay.


Right. So, I've I've saved that and um


you know, there's there's a lot of other


stuff in here that you can you can check


out. And if anything is confusing you,


if you have actually got an AI


development environment, you can


actually ask the the AI to help explain


it. So,


so here I've just asked the the AI to to


explain what this directory does. It's


going to think about it for a second or


two. It's going to run through the whole


directory, read it in a couple of


seconds, and come back to me. So, here


this codebase called Superior Agents is


a project for building trading and


marketing agents. Its main goal is to


enable automated trading operations and


marketing strategies by interacting with


various APIs. And then it goes on to


list okay it's it's got a meta swap API


that um does the actual trading. It's


got a notifications API that gets gets


environment information about what's


going on in the market. It's got a rag


API that saves the history and then it


talks about the fact that I have a


database. Um it talks about the


technology stack. So it really gives me


a lot of information. Anything I don't


know, usually the AI has the answer.


So, I'm going to go back to my


introduction here


and then I'm going to build my Docker


container


right here. And this what this basically


does is puts all the pieces together in


the right order so that you don't need


to worry about that. So, I just paste


this command in and it's going to run


for a second or two. Depending on the OS


that you're using, it might take more or


less time. Um, the Linux it's is qu is


pretty quick. Um, Windows will usually


take a bit longer,


but uh once you get to here, you know,


okay, it's it's got started.


Then I want to actually get into the


container the Docker container that I've


just built and and talk to my agent. So


I'm going to open a second terminal here


just so that I I can keep an eye on both


processes at once. So in cursor that is


control shift five I think. Yeah.


Um


I just wait for this uh this to load up.


Sorry, it takes a second or two when I'm


when I'm recording. The the video slows


things down. Uh and then I am going to


paste in the command from the uh from


the instructions here. Okay. So now I am


I'm inside and I want to run the main


script which is going to kickstart


everything.


And if you've run this before, you'll


see that the experience for doing this


is very different now because what we've


essentially done is build a


questionnaire to help you set up your


agent. So in this case, you the first


question is you you choose which LLM you


want to run. So I I put in an open AI


key before. So I'm I'm just going to um


I'm going to choose OpenAI.


You choose your research tools. So,


Twitter is one of the options here, but


you should be aware that if you want to


use Twitter, you're going to have to use


you're going to have to add in a Twitter


API key as part of the environment


variable. And they do still offer free


API keys to Twitter, but you get barely


any calls with them, which is something


to bear in mind. So, so you get maybe a


hundred usages per month, something like


that. Um, and the the prices for the


paid ones have also gone up. So it it is


if you want to if you really want


Twitter, you know, you can do that, but


it it might cost you a bit of money. You


want to be aware of that. So you can


pick what you want. I'm going to pick


Duck D.Go and Coin Gecko.


I'm going to pick my notification


channels. So all of these are


essentially RSS feeds except Twitter


mentions and and Twitter feed, which


again you're going to need an API key


for. or you can actually go into the


code and and add your own here. So, I'm


just going to pick business news. I'm


going to decide I want a a trading


agent.


And have I set up my rag API? If the


docker has worked properly properly, the


docker has done it for me. So, I'm going


to try yes, I've set up the rag. Um,


okay. So, it wants um


a little uh additional information here.


So, it wants my Coin Gecko API,


which I did not open. So, I'm just going


to


I'm just going to quickly get it here.


And again, there is it is possible to


get a free


API key from Coin Gecko, which is quite


nice. Um, if again you're you're going


to be using this like really


intensively,


you can um you can pay,


but uh if it's just a Tesco, you might


want to try the the free demo account.


Uh


so yeah, I'm going to create my free


Okay. So, you go to the developer


dashboard and you can actually set up a


a totally free key. So, I'm just going


to put this as uh


I'm going to call this superior agents


and create my key here. And then I can


copy this


and add it into my agent here.


Okay.


And it's also going to ask you for


some additional API keys. So the first


is your Infura API key. And that is


again is from is for getting onchain


information and and for uh making the


actual trades.


You can actually to get this again it's


free. You can either go to infura.io


but this has since been kind of


swallowed up by MetaMask. So you can


also go in via the MetaMask page. I have


a few of these. So I'm just going to


copy one and paste it in here. Uh,


so one second. Um, yes, I have the keys.


So, I'm going to paste in my Infura API


key.


And then I am also going to copy my


Ether scan key.


Uh, which again it's it's just so that


the bot can um can check what's going on


on chain.


And now we are good to go. You can see


it's it's got all the onchain


information that it needs and it's going


to start trying to generate some code


based on this to research the state of


the market and then make a trade. And


you can see it's it's actually writing


the research code now. Uh it's


did not succeed.


It has made a made a mistake here. So,


it's going to attempt to regenerate and


it's going to record all the failed


attempts, try again, and then record the


successful attempts, save all of this to


its rag database, and gradually


progressively improve over time.


So, I've started running this. I'm just


going to pause it for a second. I'm


going to pause both of these actually


because I want to imagine that I've


actually I've made some changes to this


and now I want to update my


my where is it? My GitHub my my repo


that I I made earlier on here.


So, in order to do that, you're going to


have to


write some actual code. Um, and I'm


going to show you the easiest possible


way to do this here, which is actually


to ask the


ask the the API about it. Ask the AI


about it. Sorry. So, what I am probably


going to ask it is something along the


lines of I'm going to specify that I


already made a GitHub repo. Uh,


So, I'm just going to ask the the AI to


give me the steps basically because the


whole theory about how to use Git is


ridiculously complicated if you're not


already a coder. So if this is if if you


don't have a whole bunch of coding


experience, it is easier for everything


just to to ask the AI basically. So here


I've said, I'd like to update my GitHub


repo at blah blah blah with the changes


that I've made in this directory. Can


you help me explain to me how to do it?


So I'm going to ask this question and it


should come up with the exact code that


I'm going to need.


So yeah, and it's done it. You can see


here. Okay, I can help you with that. To


update your GitHub repo with the changes


you made locally, you'll need to use git


commands. Assuming your local directory


home blah blah blah is is already a git


repo and is linked to your GitHub repo,


here are the steps.


So, you can uh check the status whether


you you've actually made any changes.


You add the changes that you've made to


staging preparing to to update the


online version.


you write a description of the changes


that you've made so that you're going to


be able to go back through your history


and and check that everything is okay.


And then you update the online version.


And if you have any issues with that,


again, uh it's not the easiest thing in


the world dealing with git.


The AI is very familiar with it and is


going to be able to help you write the


code that you're going to need to do it.


So yeah, thank you very much for this.


If you run into any issues or you have


any questions, please just um flag them


up on the dis uh on the Discord server


and someone from the team will be very


pleased to help out. Thanks very much.


Bye.



----------------------------------------
Prompting 101
Week 2 (June 16-20)
Essential techniques and best practices for effective Al prompting:https://www.youtube.com/watch?v=Q2Wa1Dmn6Og
Prompting 101
Hi everyone and welcome to lesson two on


how to interact with the open-source


repo for superior agents. So, in this


lesson, having um already downloaded and


and set up an agent, we're going to take


a look into a bit more about what makes


the agents tick, and that is


specifically the AI that that powers


them internally. So, obviously, you've


got a choice of models, but you also


have a choice of prompts. And how the


agents work is they're given a sequence


of prompts that instructs them to learn


about the markets, find out a bit what's


going on, or to respond to a


notification that has just come in,


whether you've set them up to receive


Twitter notifications or news feeds or


RSS feeds or whatever.


And in this session, we're going to go


through the prompts as they are now. uh


focusing in particular on the trading


agents and see how they work and also


how you can modify them to create your


own custom agents.


So on screen here you can see the


trading prompts. So these are in the


folder marked agents and then if you go


to SRC and then agents again you have a


choice between marketing and trading


agents. So I'm going to focus on on


trading for the purposes of uh this


session.


So you have uh a lot of structure about


when to when to use your your prompts


and so on that uh I'm not going to go


into too deeply here. But what I do want


to go into a bit more closely is um the


prompts themselves. So the the natural


language that is going to get sent to


the model and then we're going to


receive the model's response.


So the first of these is the system


prompt.


So what we're telling it is


what it is and what it's doing. So we


start off with you are a curly brackets


ro crypto dealer uh trader and what this


basically does is this gives it its


personality. So it in the GUI version,


the the the web client, which some of


you may already have tried, we actually


let the user pick the agent's


personality by writing in a description


of how it's going to trade, whether it's


more DGEN, whether it's more


conservative, whether it's into memes or


AI coins or whatever. So that in the


live version gets fed into this variable


here in the brackets. So whatever the


user puts in as a description of the


personality that is the the role


variable here.


Then we tell it today's date because a


lot of the time it's receiving news


stories and it's going to need to be


able to discriminate between what is


recent, what is less recent and and so


on.


Then we tell it your goal is to maximize


metric name. So this could be the value


of its wallets or it could be P&L or it


could be beating the markets. Right now


in in the main you know the the the main


branch we use the the metric is the


wallet value but you are absolutely free


to change that. And then within time


might be one hour might be 24 hours it's


up to you. We also tell it what network


it's on. So, right now it's going to be


mainly Ethereum with on mainet just


because, and here's a a useful hint. Um,


the AIS often struggle to resolve


contract addresses on other networks.


So, they they notoriously struggle at


finding soul contract addresses and and


getting those right. And quite often


they buy the wrong token, which is why


we haven't actually commercialized those


agents yet. But if you can find a way to


get accurate soul contracts uh contract


addresses, yeah, you can absolutely um


integrate soul in this. Then we also


tell it the metric state. So basically


the value of its wallets and what coins


it has. So maybe you have 50 Pepe, you


have um 100 Doge or or whatever it might


be and then the value of that in in USD.


So


this is this final line is one of our


early attempts to


prevent the agent from spending all of


its um spending all of its gas money. So


we told it the ETH balance shown is your


available balance of trading. A small


amount is automatically reserved for gas


fees, which we actually do. We um we


prevent the agent from seeing its entire


ETH balance in the hope that it's not


going to spend it. And sometimes they


they do they they run out of gas and so


on. But um this this line did not


actually work very well. So we replaced


this and this this is you know an


example of a small edit that made a huge


difference in how how the agents


performed. So we actually we took this


line out the line about the the ETH


balance and the gas fees and we replaced


it with this. Do not trade ETH. This is


reserved to pay gas fees. And we gave it


only a tiny bit of ETH and then


everything else in USDT. And this the


whole goal of this was to stop it from


spending all of its gas money too


quickly. And just changing this one line


made a huge difference to how they


trade. Now they're a lot more careful


over their gas. But we had to do a lot


of trial and error experimentation to to


get this to work and to to work out what


was the solution to this.


So then we kick off. We have an initial


research code when they've done no


research. They've got no notifications


and we actually tell them you know


nothing about your environment. Please


write code using the format below to


research the state of the market. We


tell it which APIs it can access. So


usually that would be coin gecko and


also the the duck.go command line search


or exa search depending on which we're


using. Duck.go is not actually an API


but you know who's counting.


um we give it instructions on how


exactly to write the code just so that


we can be certain that we're going to be


able to to run it and test it carefully.


Then likewise, we have a a similar


prompt telling it to do research in


response to


uh whatever the latest um


uh the latest notifications it's


received.


We tell it again what APIs it has, what


its current strategy is, and if it has


been trading for a while. We actually


retrieve


incidences when it encountered a similar


situation in the past and tell it what


it did in those circumstances and what


the result was. So that is the rag which


is its previous strategy and then um the


result which was the the before and


after wallet state.


We tell it what notifications it got and


what research it did as a result of


those. And then we tell it you need to


decide whether to trade any of the


current coins that you have or to hold


and wait or do something else. So it


could potentially, you know, decide to


tweet if it has access to the Twitter


API instead of trading to to shill its


bags. We tell it to reason through its


decision process


and then just quickly to sketch out the


code that it would use. And this again,


this is an edit that we made to the


prompt. So we we iterate over these


prompts ourselves to improve. Before we


in the original version of this prompt,


we told it just to write the strategy


and no code. And what we found was that


it was getting very tempted to write the


code anyway. And the code that it was


writing was actually quite good because


it was coming out of the same latent


space as the strategy. So it's it was


actually probably better to get it to


strategize and then sketch pseudo code


and then debug the code rather than


having it strategize and then in a


separate prompt turn that strategy into


code. So again this was something that


we learned by doing.


Then when it's done the research, when


it's come up with a strategy, obviously


if it's going to trade via via sex, it


is going to need coin addresses or the


the contract addresses. So we just tell


it to do a search and and get those from


from coin gecko if it can or Google


search if if not or do.go or or


whatever. We also have to be careful.


This this is another thing that we


learned via trial and error. the native


token address. Um, a lot of the time it


really got stuck. It was really confused


by the fact that the ETH address ETH


does technically doesn't have an address


on Ethereum because it's it's the native


token and it got really stuck trying to


trade in in a lot of cases on account of


that. So, we we had to again write in


specific instructions for that and that


was something we learned by trying it


out. So again, we we give it it clear


instructions on how to format the output


just so that we're we're going to be


able to use it in the end. And this this


gets quite long. Um we tell it to print.


We tell it what to do with errors and


and so on and so forth. Having got that,


we tell it to wait, where did I put


this? Um,


yeah, we tell it to to debug the code


that it previously sketched out


here.


And in this case, what we're assuming is


that in the previous iteration, it it


sketched out the code and put in


placeholder variables for the token


addresses, which it it it does by


default.


And now we're giving it the sketched out


code, the token addresses, and saying


debug this whole thing and make it


functional using these addresses in the


hope that at the end of the day, it's


going to come out with code that works,


that has the right contract addresses,


and that can be run immediately.


The final thing I think that is is


important here is the trading


instruments um API.


So,


one of the issues is that obviously


there are a lot of um there are a lot of


decentralized exchanges out there. Um


and the


the model kind of tends to get confused


between the APIs of each exchange,


especially if it if there are lots that


it can it can deal with. So it might


mistake it might write a call to unis


swap under the the kyber API format and


then it fails and it can't work out why


and it has to reiterate and it it just


takes a long time. So to get around that


problem, what we actually did was come


up with our own API wrapper that helps


it trade. And that is in in the file in


the directory structure here. You'll see


it under meta swap API.


And what that does is give it a


basically a one-stop shop for


interacting with the the dexes. And it's


we actually wrote this before MCP came


out, but it's it's like a homebrew


version of of MCP if you've ever used


MCP before. So again, we we tell it what


to use to make the trade. We tell it how


to write the code so that it doesn't


screw that up. And we tell it how to


um


not just not just the the format for the


code, but also what to do in the event


of of errors and so on. Uh so uh raise


every error just so that that we can we


can debug


and yeah that is it that that is the


full extent of the prompts for this


obviously we did a lot of trial and


error um in some cases we we gave it a


lot more freedom to decide okay I don't


want to trade in some cases we we


directed it very closely I


I think both both strategies have


advantages. On the one hand, if you give


it very clear and direct structure and


and a path to follow, it's going to get


things right more frequently earlier on.


On the other hand, if you give it more


freedom, it will quite often do weird


stuff and get stuck in local minima and


and


sometimes it just won't learn at all. It


sometimes it'll it'll go off and just go


nuts. But it has the potential to also


do really interesting creative things


that you didn't think of yourself and


and potentially to be more general and


more more AGI like. So it's really up to


you to experiment.


This is obviously it's a basic structure


between we're going from doing your


research, working out a plan, firming up


that plan, executing that plan. And that


is it's a solid you know it's a solid


structure but other ways are possible.


So like I said we we actually we


modified this previously


we separated out the planning and the


coding completely and based on our


experimentation we we decided not to do


that in the end. So if you do want to


change this prompt structure it is


definitely possible. We have


deliberately avoided relying on chat


history for this. The early versions did


have chat history but a it used a lot of


memory and b it made the coding


massively complex and the the prompt


structure and and there was a lot of um


you know lang chain and and different


different libraries and so on. So we


took that out and rather than using chat


history, we actually use um the


variables that I mentioned earlier like


uh like roll like um


like the the APIs like the previous


strategy. So in in the earlier version


this was this was done using lang chain.


If you've ever used lang chain you know


how complex that can get. And we we fed


this in via the chat history and and via


the model's own memory. We got rid of


that because we wanted it to be more


controllable, more transparent, and um


more debugable when things go wrong. But


again, if you know how to use lang chain


and you want to add in chat history and


you want to add in these more complex


um prompting systems that that can often


result in more humanlike outputs uh from


the model, then again that that is


something that you're free to do and I'm


really interested and keen to see the


results that you can get by doing that.


So yeah, this was just a quick intro to


the prompting structure and how that


works. And the best way for you to learn


how to do this is actually to go go and


play around with it. Create your own


prompts, create your own prompt


structures, and see what happens. Thanks


for tuning in. Bye.



------------------------------
Week 2 Technical SA Dive
Week 2 (June 16-20)
Technical deep dive into Superior Agents architecture and implementation:https://www.youtube.com/watch?v=ga8ejPUUuGk
Agir Labs Summer Residency - Week 2 Technical Dive
Hi Ron. We'll just wait for a couple of


other people to also join. I think


people are just starting to join. So


yes, sure.


How's everyone doing? How was everyone's


weekend?


Yeah, it was great. Um, many more new


things to learn and go with.


Yeah, for sure.


We're briefly going to get started


today. Also, our um one of our senior


lead engineers are also in this call as


well. So, uh we're just shortly going to


get started. Just waiting for a couple


more people to also join. Um for any of


the ones that are not available today, I


see there's a lot of note takers. So, we


will upload the recordings as well and


um share with you all. So, you guys are


all updated essentially with everything


that's happening.


Okay, I think we can get started. Um,


Fee, I also noticed that you're also


here as well, so feel free to um


introduce yourself. I'll just kick it


off. Um, so welcome everyone to week two


of the summer residency program. Um we


hope you know all of you had a good week


one getting started and learning


essentially the fundamentals uh of AI


agents and getting started with your


projects. We got um a lot of responses


with the Google forms that we sent out


or the idea forms. uh we're actively


still asking for all of you to complete


it if you haven't yet and we will get in


touch with you onetoone about your


projects to assist with you and um offer


any sort of mentorship and guidance that


um you're essentially looking for for


today's session. The idea is that you


know we really want to dive a little bit


more deeper this week into the technical


pieces to help you guys understand the


superior agents codebase a little bit


more um and go understand you know how


the essentially the the whole framework


and codebase can interact with uh


building different use cases how the


architecture works and how each


component interacts with each other. So


for this we have our engineer um he's


essentially going to you know lead um


this session go through some of the


information. We also have some of the


recorded sessions for this week as well.


So we have the model contest protocol


fundamental um sessions as well as the


multi- aent orchestration. So if you


haven't already uh please also watch


those sessions as well as they will be


very important to you know um deepening


your understanding about the overall


space and I will also share a tutorial


later in the week about how to integrate


using Google's agent kit as well. So


that will be also another session that


uh we will host and share with you guys.


But uh yeah without further ado uh feel


free to introduce yourself and I think


we can kick start.


Can you guys hear me?


Yeah, we can hear me.


Okay. Uh hello everyone. Uh I'm the


current software engineering working on


superior engine


over and uh


we um welcome all you guys uh come to uh


superior engine uh to work on and have


um new progress on how the current um AI


engine cap is and we are glad to help


you guys explore how uh to develop an AI


engine uh how to integrate with it a lot


of other tool services and especially on


the web three um interaction. Yep. So


um I think um


uh I already have some like message and


conversation with you guys on the um


a telegram group. Yeah. And um I'm glad


that uh I received some feedback about


uh how uh you run the engine and uh how


it helps you to uh leverage um the


already assist. So


uh the first thing about this session it


I will walk through the the uh code of


spirit engine and we can have a better


understanding of what current um stat of


the the framework.


Okay I think I can share my screen for


you guys.


Uh


let's see uh which one. Um okay well


hello


this see uh my current um ID I'm you


windf so it's have an engine inside and


um I view an engine with an engine


actually and right now I can specify for


you uh the the very basic structure of


the uh superior engine uh more of the


magic of spuren laid out in the engine


folder. And we have um


the ability to run uh arbitrary code


generated by the LM um model and it's


run inside a container


and how we build the container by using


uh this compose and we already have


build a default like execution


environment for the um


code engine executor we use this docker


file to view it and with this uh


requirement all the engine code right


now is uh writen in python because it's


uh we've evaluate a lot of language and


found that currently python is the more


well suit for the engine to run the code


and


um in order to run that we have a


something called container


okay uh Container manager will um


actually uh bring the call the superior


uh engine executors in this image we


execute the code um on this folder. This


folder is


been mapped with uh the


underlying image and


so it you


actually code actually located here. So


when something go wrong we call and


reexecute again. So you can see the


result b uh directory and for the data


we you


keep all the data up today. Okay.


Um so in the container managers uh let


me do a quick uh reference check to guys


for all reference. Uh we have two flow


one is marketing one is trading.


Currently the trading integrate with the


uh swap ABI. We locate them in this


folder meta swap AI. Okay. And uh a


quick summary uh on this is like it uh


where all the on trading or on the next


um uh swap or transaction perform or


even the withdraw function. We also um


do it inside the meta swap API. But uh


it's currently not public for the


security reason. So we only available


for the swap functionality only.


And for uh let go go back to the


the marketing. Right now marketing we


support uh only the uh twister marketing


and currently integrating with


uh some logic of rack and this rack uh


is using the uh


uh rack AI. Wait a minute.


Okay. Rec AI. So this is also uh AI we


build um upon the bay on the fast AI


framework and we build a rack symbol


rack function that keep first the


strategy of the engine. Secondly, a


summary of the


one circle of that. And lastly, uh it


has some feature to search for the


um what's what's called is um the uh


strategy or history of the run of an


engine.


Okay. Uh I think you guys already have


um some run on this. Uh I think I can go


with uh the metas metasi first.


Uh this one uh I can uh barbe I


currently cannot show this one for you


guys but um uh let me see I can do what


the mock barbecue we provide.


Yeah. So, okay. And then we got MVM run


uh star def. This will run the end uh in


the metas guy. Next command of file. Uh


I think I supposed to do uh npm install


first.


Yeah, you start the Oh, wait. I mean


stop first.


Wait, you guys still see my uh screen,


right? Yeah, we can see it.


Uh I can not sure which one. Uh okay,


this one correct.


I I you the dependency of metasi.


It take a while. Um this key is some uh


public key from Boke Foundation. So it


probably say to you don't don't use this


key. Okay? Don't use this key because


like uh this a lot of people will have


access to this key. So please don't use


that you your own on your local machine.


That's my first recommendation for


security.


Um the thing next is we have uh the


engine. So


let's go to the engine to speak up. So


in the engine we have um we use what


UV


u UV. So I will introduce guy uh with UV


uh this one be a very latest I I think


this is a very the mobile performance


package manager in Python and uh it very


good uh in term of you store the Python


dependencies


you guys see this right uh it requires


for you guys to install it if you want


to run the engine locally and this is


the installation instruction on the iOS


and Linus. Uh we also have the window to


do that but currently um our developer


have don't have the access to window


the actual local development. We mostly


uh on one run online and Mac OS. So this


is recommendation


from me to actually run the uh engine


locally. So we have UV


on my machine and


okay this one. Okay. Now what UV do you


start with UV sync?


So it will install all the B dependency


required for the engine. Uh okay. I


think I finish the


uh the run that


Etherum


obviously do not exist that mean I


haven't push oh I think I haven't copy


the um end here so I was supposed to be


copy this dot and yeah and return up.


Let me see. Oh, this one also need some


uh ch in term of


Oh, let me I think there is still new


update on this one. I don't know. Uh


this one. Yeah, sorry. Also this one.


Oh


Okay.


Can you run that


and well next model? Wow.


Transfer model. Uh I I think I I saw


this arrow from one of the uh intern


from


uh let me see let me see


model transfer model


dependency of


okay so if we put this one current resol


dependency so we have the transfer


control the transfer service so uh


transfer service Let's exist on this one


and then the service we use at service.


So suppose this one is uh service on


this one


sign. Oh it's sign model and we have to


provide ether service here and boom wait


this some new requirement. Okay,


make sure that's weird


function validate the model.


Yeah, it's model actually uh


in part sign.


Let me see.


for controllers and service


for service.


Oh, I think I have to inject this one.


Oh, no.


Cool. It's running. Oh, I think I should


make a fix for this one. Uh probably uh


commit it on the the engine also. Uh you


guys should follow


this one your


And also I put this one onto the Okay,


this is one better already. Uh


sorry. Uh anyone have question?


I think it's clear so far. Actually a


bug


clear so far. Right. Sorry, I can't see


your message. Uh because I I think I


minimize the


Wait a minute. Uh I update this one too


because uh I think I have some problem


with the um this RBC before they have


very limited um request for free. So I


will update that too. See? So the


current currently you can see um the um


there is one wallet is loading. So it


the wallet that actually in um


yeah from this private key. So what what


the wallet is from this private key and


the


um


the engine ID for that is before


trading. So I will show you guys how to


check that uh local 3 9 09.


I will share a different screen.


So my it's freaking hot right now. Uh


you can see my screen right? Okay. Is


known because currently I bought it


3,000. Okay.


999. Oh, I think I put this here


not wait


uh API


to


with body


not found


a minute. Uh I need to check which do


API I put here.


So global fish. So I put it on AI. Oh


it's called ABI. Sorry. Yeah. Sorry.


Sometime I forgot I


uh we have um this you can get the ar of


the wallet b on this one. So yeah this


one is the uh address of uh this driving


key.


Oh, this barbecue


uh the barbecue boot inside the end.


Okay, so


let's go back to the the


one.


Okay. Oh, I don't think it's the private


one. Sorry guys, we still have some


teaser in the making. So we use a


private revol to um handle those. Okay,


let me see. We have the um the engine


already.


So we have some um engine for uh


environment to filter but right now I


only care about open


open AI filter. So um


right now in the quick start


quick start we'll go to star first I


what I did is I um didn't do anything


much but engine execute I


source the dot uh virtual and byon net.


So this is uh very crucial because you


want to use the dependency or the bison


version that actually have all the


dependency.


So that low dependency actually laid


down in this folder. You see so uh you


have to activate that in order to use


all the dependency. So what I you can


check by which Python and actually it


show me that I'm the Python from this uh


Python uh binary dot Python here. Okay.


So right now what I'm going to do is I


run the command from quick start this


very fast one.


Okay.


So I just do the quick mock first. I


know I have this one uh trading. Yeah,


I'm not using now but I haven't open the


docker. So I think I have locker. So


with Docker version oh it's supposed to


have Docker version


combo version


here


version. Okay, I open my docu


show. Okay. Um, open it. Wait, guys.


On that uh on Mac, I have to open both


Docker version.


Uh, wait a minute. Uh, do version is


this one. up the


server.


Wait, wait.


Yeah, desktop.


This is what I recommend for you guys in


the some guy asked me about the docker


and the botman and I recommend the


docker desktop or the Rachel desktop. So


I will I will put a link later again for


you guys to like have Yeah, you see this


is on mock version.


This is all the mock version right now.


um for the actually actual


run of the um the source code or or the


feer we have a few up of this except


this one this is one uh oh


okay um I think I can


uh walk through some of the flow for you


guys


for the trading agent as I said before


we have uh


like all all the the the flow like


trading or marketing. Uh we have um DB


interface uh like


um like marketing engine sorry


about this


market. Yeah, this one. Okay. So this is


a quick comparison of how we build a new


flow in the AI uh AI engine. You guys


see this is um they a very very similar


attribute in both flow. One is engine ID


the rack the DB uh interface uh the


sensor actually they using similar


interface for the sensors. Okay. in it


and get some some feedback here and we


have uh the general interface a


contender manager a prom generator. So


in the trading sensor or marketing


sensor you have to integrate to with the


function called get metric function


the get metric function and we have


currently have two metric for it flow


one is wallet one is follower. So you if


you want to extra metric you have to


extend this function. Okay. And um we


have the gener


on on using uh on both function using


the same interface. But uh one one thing


is the general have it um various


uh implementation. We have cloud


implementation.


We got the open uh AI, we we got open


router um generate uh general function.


So if you want to add extra um platform


like um maybe Mitro or I don't know the


what the current latest one uh rot AI


from Twister or um I don't sure the


current which one is too many of them.


Uh you can extend this general function


and actually in one of this. Yeah.


Uh then uh you got a bomb generator


which which uh what kind of uh logic in


here is like it's very crucial for the


if flow that the prom generator will um


try to ex create the code that we


execute later. right now uh our whole in


the trading maybe I show you trading


right now I think you you guys uh we


have to work with uh the prom generator


a lot especially uh in term of uh inment


to do this one uh generate research code


on the marketing so this code actually


tell the engine that here is the code uh


we know that there is some swap API on


this uh tele service actually uh on the


the the left side of me. This one is


what uh tele service ABI here and use


this curve to generate the code that


actually trade the token. Okay. retro


token and this one is uh um uh when you


you want to train uh the functionality


of the code you have to change this one


and the uh marketing also trend the same


similar


okay uh I think that a quick very quick


start from the code


uh just remember that uh the more when


when you don't know how to start you go


to uh the uh


the engine flow the engine flow we have


to fly now.


Yeah. Uh sorry uh


the engine flow we have marketing engine


and trading engine. So you this is your


starting boy.


If you don't don't know where to uh when


to start, look at these two uh flow and


you will have a general idea of how the


whole flow work. Okay. Yeah, I think


that's all from my side. I miss uh you


want to continue?


I think that was that was clear. Does


anyone have any questions that anyone


wants to ask uh about the quick you know


repo walk through? anything that you


guys would like to specifically know?


Um, yeah, I I think one one guy had a


question about this arrow. I will push a


fix on on the main brand and uh you guys


can pull the latest code. Okay. I think


uh I got the arrow from the one in the


Yeah.


Uh we got fix uh fix model uh model.


Yeah. Actually do a live code for you


guys. know how to I think the whole


thing. Yeah,


this model not included in uh


Yeah, if you guys have question please


uh uh you have question right now so I


can uh can answer quickly or uh you can


push it inside so I can have some time


to read and go through all question to


answer you guys to help you guys on


board faster. Yeah,


don't be shy. Don't be shy. Yeah, you


guys you guys can come clean. You don't


you guys don't need to be shy. Yeah.


Okay, we got a question on the chat. Um,


so is asking how about integrate another


API for marketing agent like Instagram,


Facebook or YouTube. So perhaps we can


basically explain how that might also


work like. Oh okay. Okay. So yeah I I


think if you want to integrate the ABI


uh the first thing is like


okay uh this no no marketing sorry uh


marketing


uh marketing you can see uh it's getting


the default API or def from uh the


twister like SPU twister this one you


see there are lot of twister related So


if you want to increase uh uh Telegram,


no no sorry um Instagram, Facebook,


YouTube, you can change the prom here.


Make sure that when it execute it have


um like in enough of dependency or


environment variable you see I try to


use the uh I'm not also seeing your


screen uh feed in case if you're trying


to show us. Okay guys, sorry guys. Sorry


guy. Sorry. I I I I haven't. Okay. You


You see the marketing here, right? I


think


wait.


Okay. Okay. I I call you S, right? Okay.


So um very glad you have a question


about integrate all the tool uh for all


the tool uh especially on Instagram,


Facebook and YouTube you have to have


some kind of library or credential to


actually get the information or try to


do some with the API from those


platform. Uh see here I have a library


called twist. Uh twist pie actually is


the library that help us to connect not


actually earth but the engine we create


connect with twister and you change if


you want to chain with all the tool you


have to chain the bra. Okay. The brome


here you see all the bra here you have


if you want to change the whole flow


with twister you change the bra uh from


the Twister to Instagram to Facebook to


YouTube and this will reflect through


the marketing engine. Okay


that's clear for you.


Oh that's very interesting question. Um


yeah. So for the people that are


watching later, the question is how do


you um track user contacts across


multiple API calls in an agent? Yeah.


Yeah. I'm actually very interested


because like


by by context uh we we have two thing


actually uh two thing about context. Um


one is the execution


circle pass and the second is strategy


strategy uh of circle uh wait uh which


one uh execution of the current circle


and strategy of the past


circle. So this one we rely on the rack.


This one we rely on execution code. Uh


how do we know that it do that? Look at


this one. We have not notifications uh


string actually uh get the notification


from um our one of the tool and previous


strategy. Reverse strategy is actually


uh from this one and also the rack


summary also from this one. So we have


two previous strategy and rack that


do the research code research code to


actually track the context of the circle


running and


on direct also uh embed uh the metric of


the circle. So you have the ability to


uh the the the ancient had the ability


of after a circle it can have a new


result or not. If not if not had a new


result usually it will try to approach


different result. Okay


I I think that's clear for you. Uh


uh I I am not sure how to pron


this is


yeah there's another question by sash.


So he's asking for the prompt generator


function. Uh what does it do? The code


with time is gen dynamicallyed or um not


as we're building spirit agent. If not


there is any new way to do this.


Oh yeah it's actually dynamic update


every circle is create a new code inside


this one. You see I just run it create


already create new code here. So when I


actually boot the AOM key inside I if I


choose the


I'm not supposed to s key on on here but


uh if you choose one of the other option


of AM actually it's will start


generating code and put the code in here


every time it try to generate a code uh


it will have a new file here and it


dynamically generate from the LM portal.


So uh and the circle we read back from


three time actually every single try


three time for the research or the


trading. Okay


that actually dynamic tra uh updated for


the code. Yeah you can you I can check


this folder code folder. Okay. There's


another question by Adash. He's he's


just asking uh what's your favorite a AI


agent to use in case you have seen that


wasn't just chat based. Oh, it actually


um we try to like


auto uh automate the uh automate this uh


dim actually. Well, when you try engine


uh engine swam uh that are it's still in


research but uh we


try to uh engine to engine communication


and after engine communication we will


have uh punch of engine


like to run other department. So uh this


is this is our try to re we try to


research on this one and we we still in


progress on this one. Yeah. Like


automation on the whole team. Yeah.


Okay. Uh yeah


I think Su has a question. Um so he's


asking so that means prompts within


codes are dynamically updated but code


structure remains the same. No no no. Um


actually the ROM is not update but you


you guy can see the is called it uh what


do you call it blaze holder


this technical term play hoster or


holder this one is what chain is this


the holder you guys see the the blue one


I think you can see right the trend


holder the team trend b on the circle b


on the uh the resolve when it run based


on the matrix after it execute


uh the code after you execute code. So


the ROM the what chain is actually the


ROM. The problem here is uh the sum of


dynamic data of the ROM and


the code change every circle every


execution the code be update constantly


to uh if in certain case that the result


of the the metric the geometric very


like positive the the code will remain


the same but I will seek very very


rarely. Okay. So mostly this uh these uh


placeholder will change and the code


will be change constantly. Okay.


So I will get code and constantly


uh place uh holder


in ROM


change but uh the


all the part of the prom will not change


doesn't change.


Okay. Okay. I think that's clear from B5


who name Suda.


Is there anyone else that has any other


questions? Um you know with regards to


the the codebase or anything like that.


Um there's another question. Are there


any tips for measuring performance of


LLM based workflows beyond latency and


cost?


actually uh performing mostly based on


the benchmark and the benchmark very


fixed and I think it very like relate


like deep down reserve level you run if


you want to run pen mark we have a lot


of resour


circle or some long time to actually


prove that some LM based workflow to uh


have a better um performance common but


uh usually uh we will have some metric


right like what I say we we have a


metric here we have metric here so uh


metric and the environment environment


setup will be the same


so I think that that question is very


interest and


if you want to actually do a benchmark


you have to define the metric and and


the environment


you in our case with superior engine


there are two metric we care the wallets


and wlet balance mostly USD and


the number of follower is here is this


for twister okay yeah that's all our


case


hello


uh do you have question mark


happy to answer. Yeah.


Yeah. So I have a question. Uh so this


is just a code base, right? Uh by using


this we can build a superior agents


among this. I mean upon this


um you're muted in case if you're


speaking.


So if you guys have more question and


like some idea or I you can chat in


telegram I I will try to answer is a a


good bus. Yeah. Good luck guys.


Yeah.


Uh do you


Sorry we we couldn't hear you there.


you can hear. Oh, okay. I say if we you


guys have more question um


um some question about


how um we um like how to set up the new


flow, how to get a new idea of the trade


of the the code. Uh let me know in the


telegram


make some request in the fun. Oh, right


now um on the front end I think I have


to do some I have to test again. I I


don't want to to like because like we we


have a lot of feature on front end that


uh hiden in live version. So we we


cannot make uh the demo version on open


source right now. Okay. But


uh I think um we I I would like to to to


know that


we we have a very basic understanding of


we currently uh deprecate the uh rest


API in favor of uh doing the all the


service by


like we we try to remove rest API


because rest we try to reate at rest I


new version in our private report so uh


it's and the funand right now is uh


depend on the current redi so it's kind


of missy right now so we cannot demo uh


the funand on this currently yeah


okay uh you have any question yeah if


there's any other questions guys feel


free to ask and yeah for more detailed


questions feel free to just um tag Fee


or myself as well in the group or just


um DM either one of us. Um yeah, Fee is


in the group chat as well. I'll also


message his Telegram ID here. So you


guys can essentially just also drop him


a personalized message and if you just


prefer to just talk over in the DMs,


this is his Telegram ID.


But yeah, if if no other questions guys,


um I think we can essentially hand it


off today. Um we'll keep you guys posted


with the rest of the week stuff. Um


again, you know, I would say like get


started with your projects. Anything


that you guys need, feel free to let us


know. Uh we'll be getting in touch with


you guys in regards to the form that you


have um submitted. If you haven't yet,


please make sure to do that. Um we also


have some sessions scheduled about the


agent kit. So I'll also share that with


you guys as well. um along with the


judging informia you know judging


criterias and who's going to be on the


judging board and next week I think it's


going to be more um calls with external


partners that we're also going to bring


in so some of our industry experts and


leaders that you guys can also integrate


with your projects to get more ideas um


but yeah without further ado I mean I


would say good luck with the rest of the


weekend building and uh we'll see you


guys


Hey guys.


Hey guys. Good luck. Good luck guys.


-------------------------------------------
Live Vibe Coding Session
Week 2 (June 16-20)
Interactive coding session demonstrating real-time agent development:https://www.youtube.com/watch?v=buq0-CmpD1Y
Agir Labs Summer Residency - Vibe Coding Session
I'm going to wait for a couple other


people to join and then we can get


started.


Hey, sorry. My camera has some problem.


One second. I'm just going to try and


fix it so that I at least have camera.


Yeah, no worries. My bad.


Okay. Uh oh, nice. I've got video now.


Um


Okay. So, let me see who we who we've


got because I did want to Someone was


asking about um the CFDs. Uh, and we


have


Adit who made that. Um, so I'm just


going to send him the link and bring him


in. One second.


Uh,


yeah. Otherwise, what I would like to do


with this session is I'd like to vive co


some edits to um


to the superior agents setup. Uh


I was going to do different forms of


trading, but um


sorry, I need to admit the uh


need to admit the the note takers


manually. Um Oh, I I didn't do it on


purpose, Jen. Oh. Oh, sorry.


I was just not doing it because I think


people were bothered about them like


last because they keep sending emails


everyone. But it's fine. I'll just Oh,


okay. Well, the new ones I will admit.


Okay. I'll I'll do it. No worries. No,


no, it's No, it's okay. We We can do


without. It's It's okay.


Um Yeah. So, I thought about doing a


trading app. Uh but actually I I want to


do something totally different. So I'm


going to try hopefully to do a um a


recipe app. So turn turn the superior


agents into a recipe into a superior


chef


uh to make uh recipe recommendations and


then hopefully improve over time based


on which recipes you like and which


recipes you don't like. Um,


so I I'll share my screen for now


because I don't know when Adit is


joining, but um, and then we I'll I'll


go from there. Uh,


where is my screen share? Okay. And I'm


I'm going to totally vibe code this.


Like I'm I'm not going to I'm going to


try and write as little as possible


myself just to demonstrate that it can


be done hopefully. Um


right so um


yeah I think um part of the problem was


um people were sort of stuck for ideas


so I did want to do something that is


totally different from uh


from what is available


and I've got a moment of doom if cursor


isn't even loading. Oh okay. Yeah. Now


now we've got it. Um,


okay.


Oh, great. Um,


yeah. Well,


start by start by broadcasting all of


the keys. That's um that's a plus. Uh,


they were uh Yeah.


I'm going to be going to be deprecating


those uh immediately. But um yeah. Okay.


Um so yeah, this is this is essentially


the basic superior agents um set up. I I


already had it um so I already cloned


the repo to my desktop. Uh and you can


see I was doing some testing here and uh


last time I last time I had it open, but


I I didn't change anything beyond adding


the the API keys.


So, that is that is essentially all that


I've done. Um,


so I'm going to go into the agent


section. Uh, and I'm going to start with


Yeah, I'm going to start with the the


marketing agent,


I think, because that that is the one


that is closest to to what I want to do.


So, um,


I'm going to type in my try and rely on


the AI to to help me build this. Uh,


oh, I thought I had the model list here.


Oh, and I can't even get it. Okay, never


mind. Oh, no. It's my other PC that has


the uh that has the model list. Okay.


Um,


yeah.


Okay. So, I'm I'm going to start out by


just giving it like a a basic


description of what I want to do with


this. I would like to turn this social


media marketing agents into a recipe


recommendation agent. The user should


user should be able to enter a list of


ingredients that they have and the agent


will search the web for relevant


recipes. When the user picks a recipe,


it should be saved


to the rag database for future


reference. is an example of something


the user likes. So, let's hope that


it comes up with something interesting.


So, it's it's come up with a strategy


for what I should do.


Um,


it's also actually started um started


writing it, which is nice. So,


right, what do I need to do? First


thing, rename and rename and refactor.


So, change all the references from


marketing to recipe. the class names,


the variable names, etc. Update doc


strings and comments to reflect a new


purpose. Yeah, that's solid. Update


prompts. Yeah, I definitely need to do


that. Change the agent workflow. Instead


of maximizing a marketing metric, the


act the agent should one, accept a list


of ingredients from the user. Two,


search the web or use an API for recipes


that use those ingredients. Three, print


recipe options to the user. Four, when a


user selects a recipe, save it to the


rag database as a liked recipe. Four,


update dependencies. Um, remove or


replace marketing specific dependencies.


Okay, that's that's not urgent. Five,


update rag usage. Store selection


recipes in the rag database as positive


examples for future recommendations. So,


yeah, the the AI's got what I want to


do. So, it's going to give me a


stepby-step example for refactoring.


Um,


so, uh, what I should be able to do is


I'm not actually sure if I do want to


apply this right now because I am


worried that a halfass refactor by the


AI is going to break other things.


Um,


but let me see.


Yeah, I I don't want to I don't want to


rush into it using code that is just


written now. I want to make sure that my


changes are as secure as they can


possibly be. So, I'm going to ask um


Actually,


no. I've changed my mind. I'm I'm going


to apply this and then I'm going to ask


it to do the next section separately.


That probably makes sense. So, it's it's


now editing my code hopefully


successfully.


Uh I can see the changes that it's made


here. Um so, that's that's the old one


and


hopefully


Okay. Yeah, this looks good. So, I'm


going to accept the changes that it's


made.


Oh, yeah. No, it's it's made the change.


I just have to check that because my I


have a couple of different cursor setups


and one of them doesn't always do the


changes when it's already done. So,


so yeah. Um


that looks good. Okay. So, now I'm going


to ask it how to uh to help me with the


next steps. Uh


so again I've got a


I got actually quite a long answer. So,


Right. Where are we? Um,


okay. So, yeah, I need to change the Did


it Did we already rename this as


marketing? Um, as recipe.


Okay. Yeah. Uh, so I have


I'm going to look for


I'm going to look for all instances of


marketing agents in the


Yeah. So I have 12 instances of


marketing agent and I'm going to replace


it with


the agent.


So hopefully that has caught everything.


Um


and that should have replaced all


references to it across the entire


codebase which u fingers crossed. Okay.


Uh two update the constructor. Okay.


Change the type of prompt generator from


marketing prompt generator which um we


have here to to recipe prompt generator.


Um


I just want to make sure that we haven't


used this anywhere else.


Search for this again.


Oh, wow. No, I I do reference this


elsewhere. Okay. Um, fair enough.


So, I'm going to switch out that.


Uh, remove update any marketing specific


dependencies. Um, eg marketing sensor.


Um,


I am not sure if I want to currently do


this. Um,


yeah, I'm not going to I'm not going to


mess with this for now. I'm going to


leave that.


Uh, remove all refactors and methods


that are specific to marketing. Um,


again, this we've already done, I think.


So,


Okay, I'm going to This would take a if


I if I want to double check whether it's


done a good job on these manually, which


I actually really should, um it would


take more time than we have this


afternoon. So, I'm just going to um


you'll lower it and hope that it works.


Uh so yeah


uh so whenever you instantiate the agent


you um


use recipe agent on recipe prompt


generator. I think I've fixed that, but


um yeah, remove refactor. Um I'm not


going to do that for now. Uh


yeah. Um


Okay. So, now I'm getting it to to debug


debug my recipe for me. Um,


so let's see what it's found. Uh,


I still import marketing center, but I


don't use it in the recipe. Uh, okay.


Yeah, I will


I will get rid of that because it's it's


unnecessary.


Yeah.


So, well spotted AI get rid of that.


Uh the recipe agent constructor no


longer takes a sensor argument but the


doc still doc spring still refers to


marketing related.


Um


okay.


Wait. What? Um


Oh, I see. Yeah, they're taking it out.


Okay.


Okay. Yeah, that's been taken out,


right?


Um,


you rag save method. You use selfs save


rag example self aent ID uh kind of


recipe. Make sure that save example is


the correct method name and signature


for your rag client.


Um I am not


uh we updated the rag um recently and


I'm not actually sure if this is um


oh if only um if only PE was in to help


out. Uh let me see where else we use


this.


Um yeah we are running it here


which it just rewrote. Okay.


Okay, I cannot remember this. So,


That's probably easier than me searching


through for it. Um,


yeah. Oh, okay. It's not the right


method. Good. Um, spotted the fix. Uh,


there's no method name. So, in


mock. Okay. Um


yeah, we're not wrong. Um


okay, instead the same the main methods


for saving data are save result batch


blah blah blah both expect a list of


strategy data objects. Okay, so they


should be expecting recipe data.


Um


great. So we've got to fix


I am not sure which one of these expect


which which expect


So you can see I mean this I I am vi


coding this uh but


uh I'm also bringing in a level of


experience like knowing that okay


some of these seem to be expecting


springs and I mean some seem to be


expecting lists. So I need to um I need


to factor in that. Um


okay. So I and what's quite nice here is


you can see it's it's trying to


reconcile the the old and the new code.


So even though I'm writing a recipe,


it's seeing it as that recipe is like a


strategy for answering the question. So


I'm passing it. So it it's recommending


that rather than kind of faffing about


with types, I just pass each recipe as a


oneelement list and handle it like that.


So yeah, I


I think that's a lazy solution, but it's


um


an okay one. Um,


and I think for the for the scope of


this program as well, Jen, I mean, it's


always okay to do these like band-aids,


you know, solutions for everyone because


the idea is just to build a P that just


works that they can present and, you


know, has the use case. Yeah. Yeah.


Yeah. And I I don't want to get too deep


in this, so I've been skipping over


stuff that I really should check um just


to to kind of demo a very quick run


through. Um


so I will yeah I'll apply this but yeah


I I think people who are sitting in can


kind of see how I am doing this uh which


is just kind of asking the AI questions


and and trying to feel my way towards


towards a working app. Um,


so, oh, I I will actually I'll one


second. I'm I just want to check if um


Oh, Adit is in. So, um, yeah. So, I uh


because I I don't want to go on too long


with my with my cooking app because


Adita actually has a he he viodated a


functional app last night for for


trading forex. So, uh, I I'd like to


bring him him in to talk about a bit


about his app. I'll just quickly wrap


this up. So,


you can see that it's it's providing me


with a mixture of sort of advice and um


and and straight up code. Uh, so then I


obviously I go through the list and I


follow up in each part each part that I


don't have a full answer for. So, tell


me to create a unique ID. I'm pretty


sure there actually is already a user ID


in this, but I will make sure. So, um


Oh yeah. Okay. So yeah, I I already have


this which is nice. So I I don't need to


write it.


Uh


if I want to use the D4. No, I don't. I


won't bother with that. Um,


so now that I have


I've made some changes, I don't think it


is going to be


entirely


perfect.


Oh, it doesn't it doesn't like my Python


style, which yeah, fair play. Um,


uh, so I


I've done the urgent stuff. So, what I


can hopefully do now is actually um


uh


I always forget how to how do you close


one terminal? Um


uh there you go.


So, yeah, I've I've made some changes


and what I want to do at this point is I


think test it. So, I can just go


straight to um


uh I can go straight to the the readme


which should work in the exact same way.


Um


uh the oh sorry the quick start. Uh


and like an India I I'm running this on


my Windows PC. So, uh, but yeah,


um, if if I was running this on my Linux


PC, um, it would be, uh, it would be


easier, which


what what is it? Someone remind me of


the Windows commands for this. I can't


remember what the Windows ones are. Um,


all they all they really have to do is


they just need to set up the the window


Windows Linux shell and then they they


kind of go from there. But it's almost


the same everything. Yeah. No, I I I


don't think I have that on this PC. Um I


I don't think I have the uh I can send


you the guide if you want. I just helped


someone set that up the other day. Yeah.


Yeah. No,


yeah. Uh sorry. Normally I do this on


Linux, so um I can't remember how you


how you actually do it on


this. Uh yeah, let me uh let me take a


look at the guide.


Okay.


And you can check with this as well in


case you found it.


And all those pseudo settings,


everything should work fine afterwards.


Okay.


Oh, wow. No, I do have it installed in


here. Okay. All I ever use this for is


PowerPoint. So, I


I didn't realize. Okay.


Oh [__] I'm in the wrong terminal


again. Um,


Right. Um,


okay. Now what?


Uh, I can't actually remember if I have


any of this stuff.


Oh,


help me out. How do I How the [__] do I


do this in Windows? I think from there


on you just have to activate it inside


of the um the Windows shot. But that


that's all I know because I don't have


Linux either. But when I help someone,


it worked out. Okay. So, how do I


activate the WSL on this?


Because I thought I Yeah, it should be


it should be live, right? So, I can't um


Yeah, you should be able to use the


comments there.


One sec. I'll help you suggestions.


Uh so you are in the actually in the WC


root engine.


Yeah. Could you please type sudo app


update?


Okay.


Okay. Here this one.


Yeah. I I just want to update WSL or


just do a general. No, that's updating


the packages. So yeah.


So yeah that's WSL and we can just we


can just type the commands in there.


Okay. Um now


uh so for running the


like uh there were a set of commands


right for running this whole thing.


Uh


in my version I just uh like made a


script for running it in the windows.


Oh, okay. Uh


oh, it'd be cool if you could actually


share that because that that would


probably be useful to everyone.


Sure.


Okay. So, is it possible for me to do on


the terminal from here? I've never done


this using WSL, so I don't know how to


do it.


Uh, I also didn't do it in WS. So,


none of you use WSL. Okay. I don't know.


Yeah, I'm not sure. I haven't I haven't


run through the full settings on


Windows, but from what I know after the


WSL, all the um the steps are the same,


but I'm not sure. Yeah, all steps are


actually the same. Yes.


Yeah. Okay. The docker could not be


common docker could not be found in this


WSL2 distra. Um


I don't know. I mean I guess that means


I need to install Docker, right?


Yeah.


Uh,


I can send you the profile as well.


Just send it.


So,


in the WSL, I think once you do these


ones.


Oh, [__] I didn't mean to do that.


Sorry. Um, yeah. What? Uh,


I'm sending it to you. I'll send in. Do


you want me to send here or you send?


Yeah. Yeah. Wherever. Anywhere is fine.


I'll send this. Let's Let's try this.


Okay. Right. Uh,


okay. Okay, got it. Thanks,


Oh, I'm going to have to stop.


Okay, that looks very much like it


didn't work. But um


yeah, I don't know. Um I


Yeah, my feeling is that it didn't work,


but um


Yeah. No, I don't know what's what's


going on with us.


Yeah, I'm not sure. This is the one I


could fall on, but I don't use Windows,


so I'm not sure. I apologize. Uh,


okay. So, how about we I I was going to


show a quick debug of this, but if I


can't run it at all, then that is going


to be uh that is going to be tricky. Um,


and Edit, I don't suppose you've got any


suggestions for how to deal with this?


Uh, so how about installing Docker


Desktop?


I think it would be easier and better.


Uh, to do what? Sorry, you're a bit


quiet.


Hello. Yeah. Yeah. I was thinking about


installing Docker desktop.


Uh, starting Docker desktop. desktop


app. Oh, uh, Docker desktop, you mean?


Oh, yeah. Yeah, I can try that.


Yeah. Yeah. How about we uh run that


command every I don't know if this will


work.


Uh, do what? Sorry. Uh, running that


command again.


Uh, in the terminal.


What? Running that command again. Oh,


with this open, you mean? Yeah. Like,


okay.


Uh.


Oh, okay.


Yeah. Yeah. Oh, yeah. Yeah, we got it.


Oh, nice. Wow,


that's that's some windows deep law.


Okay. Um


I did not know you needed the window


open to make that work. Wow.


Okay.


Um so I've got I've got an M I've got an


M file. So um yeah, that's that should


be fine.


Um,


no. We said follow directory.


I thought I had this. I thought I made


this, which I might not have done. Um,


Oh, yeah. I might not have an uh that


specific part. Let me um


How the hell do you How do you see


hidden files in um in Windows?


Um it's an option in the view.


Okay. I I've I've given up these I've


given up these keys for lost. So, um,


yeah. How the hell do you see hidden


files? Is it It's in options, right?


Yeah. Uh, the view.


Okay. I not I think it's the view. Not


Okay. Not this view, but uh like the


three dots. Yeah. Okay. Oh, yeah. You're


right. Um


uh


Yeah. Oh my god.


Well, like


Okay. So, it should


this we should have. So um


this is supposed to be demonstration of


how effortless


uh


do compose quick start does not exist


but uh it clearly


You know, do you know what I'm missing


here? Cuz it there is a M file


somewhere, but I don't know if it's the


wrong one.


Edit, you know, any idea?


Any idea at all? If not, we'll give up


and we'll you can demo yours. But um


yeah,


but yeah. Yeah. Yeah. Any idea? Yeah,


you're muted in case. Yeah. Oh, sorry,


sorry, sorry, sorry. I was talking here.


Yeah. So, I think uh there was bootstra


of that sort of file. So, you were


running that in the video that was in


the


Yeah. How about we running this


if um Oh, wait. Try try running this


just like


uh


do


Oh yeah.


Like I think you got spelling problem.


Yeah. Oh, I'm in the wrong one. Yeah.


Okay. I tell you what, this clearly


isn't going to work. So, um do you want


to demonstrate yours since we've only


got like 15 minutes left? Yeah, sure.


Okay. Yeah. But anyway, that that was my


attempt at showing how you can make some


quick edits, but unfortunately I did it


on the wrong PC, so it's been kind of a


disaster. But um yeah, it will show you


a much better job. It's going to be


great.


Oh,


and I'm saying overall like you know


it's it's clear to see that it people


are able to build custom use cases just


using I mean cursor or even other tools


essentially to build on top except the


you know windows um difficulties that we


we kind of ran into unexpectedly.


Yeah.


Yeah. Okay. So


uh yeah this is the superior raisins. So


I have converted this to forex


environment. It was actually in the


crypto environment. This is audible


right.


Hello


see your screen. It's it's yeah okay.


Okay. So this is actually converted to


forex environment. So, uh what I


actually had to uh look out for is that


the crypto environment had uh show you


the yeah when looking at the scripts was


actually crypto. So, uh what we had to


change is that the crypto broker was


changed. The the uh like APIs had to be


changed. The news had to be changed. And


I will show you the example of


[Music]


yeah this was the example of uh the


crypto one. So


in


when we come to this uh we just used


IPA. So this was used for forex trading


and they had an example uh demo account


which we could trade for free. So yeah


this was used for making the orders and


we also used the alpha mandates which is


used to fetch the news. So this news had


a play in uh deciding the factor for the


the trade if it was buy it was uh like


if it was buy or it was sell


and yeah this was for the marketing I


have actually not used this here and


yeah that was the initial setup


and uh yeah if you just let's just run


Yes.


Yeah. So this is the


[Music]


Yeah. So we actually take the uh pairs


uh for this is euro to USD and analysis


is being done on that and after the


analysis the like we have actually


supplied an open router API. So it is


passed on to that onto that for an uh


like the decision making.


So yeah, you can see that the trade


executed successfully. Uh Jen, if you


could show the uh if you could show the


dashboard, then it would be nice,


right? Oh my um so the uh you mean the


um the dashboard? Yeah, let me let me


just bring that up. I don't have it on


my PC. I have it on my phone. So let me


just I'll I'll just sure. Yeah, I don't


have access from here.


Okay. So, it actually performs the


analysis on all the pairs and actually


decides what to buy or what to sell.


Yeah. The same pick button uh for us. So


you can actually convert this to


anything


and like we have actually also put uh


limitations on how many trades that we


that we can execute a day for the safety


purposes and also uh like for that


purpose we have also implemented the the


maximum quantity that we could buy. So


it's now kept as 1,000.


And yeah, here we can see that we have


executed three trades


and this runs


in the interval of 60 seconds.


Yeah. And today there will be no days


like we could extend this


much more further but this is the basic


idea that I'll come to.


Yeah. So that's the link. Yeah, I've got


the dashboard. So I'll just quickly show


my dashboard. Um then I will stop.


Okay. Uh


so yeah, if you guys can see this.


So we managed to lose um we lost we lost


$75.


So yeah, we're we're crushing it with


but it works. You know, you can see you


can see in the dashboard and this is


just the demo version. This is the test


API. It's not live API. Sadly, I don't


have $100,000 to spend on. But um yeah,


so you can see that it is actually


connected up and it's actually using my


account, which is uh which is pretty


nice. Um so if we would want to take


this further then we could actually use


the feedback system like like the rack


system is actually configured but not


being actually used. So uh if you want


to extend it further I just wanted to


build this for demonstration purposes so


it'll


uh execute it properly.


Yeah.


Yeah. So, I don't know if anyone has any


questions about this.


Uh


yeah, if anyone has any just um


feel free to uh


to share


um whether that's in the chat or if you


just want to speak up and go ahead. Um


yeah.


I think there might be questions.


Okay.


And it's also if you can have the the


Windows script that you ran maybe push


to the repo. I think that might be


beneficial because I I communicated also


the people that had the issues, but I


think there's still some um that might


be running into that are maybe not


communicating. So it might be beneficial


to just, you know, point them there to


run it.


Yeah.


Yeah. No, I I think that's a solid idea.


So, um yeah, we should do that.


Yeah. Yes.


Uh Jen, you have that, right?


Uh which one? Oh, the one the one for


your um your trading. Yeah. Yeah. Yeah.


Yeah.


Yeah. Okay. So, this the script is in


there, right? Yeah. Yes. Yes. Okay. Um


Yeah. Is that repo open source as well?


Is that available? Yeah, it's public.


Okay. We should we should also share


them as well. Okay. I I managed to


meanwhile I managed to fix mine.


I know what I know what I [__] up now.


Um it's the um the the quick start the


end quick start was in the wrong folder.


Um so


uh so I'll just quickly share and we can


see what other errors I've got in in


this thing and and hopefully I'll just


quickly ask the you know ask the um


uh the what do you call it the uh


uh the the AI to debug and see see how


it handles that on second um


Yeah. So, it's um it's doing its best to


set it up right now. I fully expect that


when it it does when it manages it, it's


it's not going to work because there are


going to be errors in here. Um


but I'm I'm curious to see what happens.


So yeah, it's uh you can see it's it's


it's trying to get this thing set up in


in its little docker container.


It's it's it's a lot slower on Windows


than it is on Linux. And if I I've only


ever done this on Abantu before and when


I've done it on Avantu, it takes about 3


seconds for SL. So it's so fast. Windows


is a lot slower.


Yeah. But yeah, so this I mean you can


see I even with even with my screw-ups


on my side which is you know entirely my


fault for using it do doing this for the


first time on an unfamiliar OS.


This took me like half an hour. Uh and I


I have something that is it's trying to


run. It's doing its best and I have you


know a base on which I can iterate and


then and then keep improving.


So I I once this is running, what I'm


going to be able to do in this is see


what errors I'm getting when I try to


interact with it. And then as I fix


those, I can also kind of make iterative


improvements. Like maybe I want the user


to be able to grade the recipes after


they've made them. And like not just


choose I don't I don't just want to save


the ones they chose. I want to save the


ones they liked as well, for example. or


I want to add on a front end to make it


so that they can interact with it like


this. This would be really cool as a


telegram bot for example. We we could


turn this into a telegram bot rather


than you know something that runs uh


runs locally on a PC like the trading


agent. I could uh I could set this up so


that you can you can you know I host it


and then you can access it on your on


your phone.


I can also do stuff like tidy it up. So


this this is still it's still running


the meta swap API which obviously I'm


not going to need if it's a recipe


agent. So one of the things that I can


actually do is just either comment out


or get rid of these. Um because


obviously we we don't want to we don't


need to trade if if all I'm doing is


searching for recipes.


Uh and then yeah basically as as much


assume you can get a basic version of


whatever your idea is in an hour or two


and then just iterate on top of that and


keep improving it and and asking the AI


questions like um I I mean I can ask um


Um,


so yeah, assuming I want to slim it down


and stop doing all of this meta swap and


and everything, I can then ask the the


AI how I can actually tidy it up, you


know, get rid of stuff that I don't need


to run that that are taking the system a


long time to set up, like the metal


swap.


So I can here it's reading through and


trying to work out what I can get rid of


to make this run faster and and load


faster. So yeah, it's


it really is this quick to to do a basic


app of your own and then from that point


on it's just a question of debugging and


improving and making a better front test


and so on. And the the AI is going to


help you with that. It's It's listing


all of the stuff now that I can just get


rid of, which is great. Um,


yeah. So, I guess uh any any other


questions


because if not, I guess we will we'll


wrap this up. But what we really just


wanted to show is that it is possible to


do totally different things with this


quite easily. Um, for all my OS


problems, I still managed to get this


running as a recipe agent rather than as


a uh as a trading agent. And at least


managed to get um to get his to actually


trade forex uh really quickly. So I I


gave him I gave him access to the to the


Wanda code sort of 5:00 last night and


he just implemented it really quickly.


So if you have if you have a wonder if


you have Robin Hood, it's it's really


easy to switch out. So yeah. Um


I guess that's kind of everything. So I


just wanted to say yeah, thank you for


joining. This is going to be recorded.


It's going to be shared on on the group


and everything. And um yeah, please


continue to ask questions in the group


and uh and we'll I'll also share Adit's


repo where he he does this and uh where


he has the the script for loading


everything. So air did I forget anything


or is it is it all good? No, I think I


think that's all that's all. Jack, we


covered everything.


Great.


Uh so yeah, thank you very much and um I


guess have have a good rest of the day


wherever you are or rest of the night.


Um cheers. I see you all. See you


everyone. We'll share the recording


shortly. Cheers. Bye.


Cheers. Bye.


---------------------------------------
Week 3 Judging Overview + Project Dive

Week 3 (June 23-27)
Overview of project evaluation criteria and deep dive into project development: https://www.youtube.com/watch?v=6sgsFZE5qFk
Agir Labs Summer Residency - Week 3 Call
Hey, Ron.


Hi. Hi there. Morning.


Hi. How are you doing?


Uh, I'm doing fine. How are you? I'm


good. Thanks for asking. How do you?


We'll just wait for everyone to


and then


we'll go from there. Let me ping that.


Yeah, sure.


Hey, am I audible?


Yeah, we can hear you, Jen. How are you


doing? I I have to mess around with my


with my a bit, but


it looks It looks good. Everything


sounds fine as well.


Yeah. So,


we'll just wait for everyone to join.


Um, I see there's a lot of not takers


again. I'm not sure. Should I let them


in? Uh, I don't It's It's up to you. If


you want to boot the note, I I don't


object.


Yeah, I think it's it's fine.


I think we can start in like three


minutes and then um yeah we'll get


started with the you know then judging


sheet um the criterias internally and


then we can maybe ask you know the


people that join essentially to do a


quick pitch give them feedback and see


what type of questions they have as


well.


Yeah that sounds good. Um


cuz yeah, I think we uh it's


one of the things that we want to get


across um particularly in this court is


that obviously making an agent is part


of what everyone's going to be graded on


by the judges at the end, but also the


ability to kind of present this agent


and and what it does and you know


explain to us why we want your agent


basically. Uh that is that is a


component of it. So it's it's good to


start practicing as soon as possible.


Yeah. No, for sure. I totally agree. And


I've been communicating with a lot of


people as well. So, um there's a lot of


people that have been joining meetings


that are also progressing. So, it's it's


good to hear that some people are


already they already shared some UIs. Um


they're they're progressing through the


projects.


Okay, let me also everyone gets


notification. But I think we can get


started. I mean here we have Rohan and


sir sir I think if I'm pronouncing name


correctly in here also let them not as


well so they also get theation


let me screen share


perfect


on screen


yeah yeah you can see it perfect So


essentially welcome everyone uh once


again to week three of the summer


residency. If you're watching the


recording essentially in this call we're


going to go over the the judging


criteria and we'll explain how the


judging will work as as well as the demo


day as well which will happen on July


9th 5:00 p.m. HTT. We sent emails to all


of you and then later on in the call


we'll ask you know some of the live


participants to share more about their


projects their status Q&A as well as um


we'll give feedbacks about how you know


they can do the presentation at this


stage you know most of you have gone


through um the recordings you know and


got started with your agents


participants that I talked have got


their agents so far um just a open


source repo which is great um so I think


from here essentially the goal this week


is to really get prototype running and


that you know we can give some feedback


and you can continuously keep building


on top um to essentially have an MVP


like experience ready for next week.


So we we have couple of pillars in here.


The first one is technical skills. The


last one is presentation and


communication. The idea that we want to


explain to you guys a little bit in


depth about you know each one of these


pillars and how you can essentially you


know pace your project but also yourself


and your submission uh for for success


you know and with keeping these um


criteras in mind. So each one of our


judges will score these scores out of


fives. uh we will essentially mark them


internally with our edges on um scoring


criteria and then the top five you know


the projects that land up will be the


ones in the demo day. Then maybe do you


want to explain a little bit in that you


know what do you expect you know being


the chief AI officer from a technical


skill but also from a creativity point


of view and the rest of the pillars as


well.


Yeah sure. So obviously um all of the


judges are going to be coming to this


from a slightly different perspective.


So I'm just going to kind of focus on


mine, but I I can say we we're we've got


some nice highle judges if you want to


um get people looking at your projects


who have the power to you know help you


fund raise, help you um ideulate, help


you grow into potentially a whole new


business. And we've got people from


Animoka and from various um various


other um big ecosystem players. So


they obviously they're all going to have


their own takes, but they're all going


to be using the same form. So you can


you can kind of get an idea of the um


the criteria and the waiting here, I


guess. So


obviously technical skill is a


is an important aspect. I'm not going to


say the only one because obviously


there's there's a lot of others. So, and


a big part of the way we designed this


project was to make it not exclusively


for people who are like, you know,


computer science, PhDs and all the rest


of it


because we part of the reason we wanted


to do this is to demonstrate that these


these agents can be used by everyone.


So, you don't need necessarily need to


be doing like the most high-end computer


science stuff um possible to score a


high technical skill aspect. It's more


like what I would say um


it's it's applying what you do know in


uh a nice way. So, I I've kind of vioded


apps before and a big part of what I was


saying when we when we were doing the vi


coding session last week was


that this vi coding you can get


something to work but what it will also


produce is is kind of spaghetti that


works basically. So, um, what you can


then do after that is you can debug, you


can make it past, you can make it, uh,


neater, you can take out some of the


spaghetti and and make it, uh, you know,


make it look less like it was


hallucinated and then coerced into


working.


Um, and it's it's not purely, you know,


is this code beautiful. I would say if


if you've got a really nice mechanism


design behind your your agent or you've


got a really nice reward function going


or you've got a really nice um nice


maths or or whatever then that that also


comes under technical skill uh


creativity um that is very much based


around you know how original your Asian


concept is. Um,


so I I demoed one last week that I


deliberately wanted to move away from


the applications that we already have,


which is kind of finance and social


media. So I did a a cooking one last


week and and turned it into an a for


telling suggesting recipes to to cook


with whatever food you've got and and um


improving its suggestions based on what


you like and what you don't like.


So yeah any any kind of application that


we didn't think of yet that that is that


is something that is interesting that is


something that shows creativity or


alternatively I would say you know an


application that we did think of like


trading but applied in a a totally


different way. Um so again that that


would be creativity.


So yeah I also I also do want to add on


the creativity piece as well. So I've


been talking to some particip


participants for example someone is


actually building an um like an email


drafting sending a meeting scheduling


tool um that they're they're building


out and the idea is that you essentially


have a one single you know kind of like


a framework to type out emails hey send


an email to this person about this


information and it schedules it sends it


out so they're asking hey like how can I


integrate this framework right even even


at this stages like there's so many ways


to integrate the the self-learning you


know daringism mechanism that we have


like I told them for example you can


essentially learn from how many user


graphs that the the agent does and based


on that it can perfect emails over time


right so I'm sure everyone in here


almost uses you GPT or other other tools


for you know revising messages fixing


them and sometimes it can become very


very messy so really having having the


agents integrated on top of this to


understand you know the the click rates


or the meeting acceptance you know these


type of metrics even at these stages it


can be integrated so there's so many


ways that I think creativity can apply


just essentially like Jen shared um it


really matters not you know how much you


guys are pushing for um even if it's


like a totally unrelated nothing finance


related project it can still make sense


as long as you you've thought of the the


use case together yeah and I what I


would also add to that is um creativity


includes includes the content And it


includes your business plans of the sort


as well. So if if you're making a


trading agent but you've made a whole


new that is just wow then yeah that that


gets scored high on on creativity even


though the use case is still the same


they use. So yeah there there are


different ways to kind of collect that.


um business potential. Obviously, um


some of the judges are going to be on


the tech side, but some are going to be


on the business side. And what they're


going to be looking at more for is um


the,


you know, can could this make money?


Could I could I put this on the internet


now and start charging for it? Um,


and


that is going to be the I guess the


aspect that is closest to pitching to an


actual VC, which a lot of the time is


quite frustrating because the VCs all


have their own vision of their ideal


company and it's never the same vision.


So, one guy gives you recommendations,


you adapt your pitch based on that, and


the next guy wants something totally


different. So, this this one is hard to


do, but it's also tied in with the the


last item on the list, which is


presentation and communication.


because obviously if you have the best


app in the world and you don't tell


anyone about it, then it's not the best


app in the world. Um, so part of having


this uh is to let people know about it


and to show it off and and get people


interacting as much as possible. Um and


that that can obviously be a place where


if you are just purely tech focused, you


might want to form a team because uh


usually even you know every startup that


you you have usually there is one tech


guy and one one BD guy. So um Julian's


the BD. I'm I'm technically tech. Uh but


um yeah. So um


yeah, those are those are the grading


criteria. So it


if you you're looking at your project


now and you think okay well I've got


I've got high technical skill but um I I


didn't really change the framework much


much then what you might be thinking is


okay well maybe I want to make a really


great transend so that users will will


want to use this um rather than uh


rather than any of the alternatives and


that that also increases my score for


business potential and and for


communication something like not


essential.


Um, yeah. No, no, no, go ahead. Sorry.


Yeah, I was going to say definitely like


if even like Jen said, if because the


people are, you know, still thinking of


ways that they can really customize


existing framework and add on top and


you know, they're saying I have some


great UI UX skills, front end skills,


like there's always ways to innovate it.


The idea is that also and I do want to


remind that as well there's still about


two weeks to go and we're not expecting


everyone to come up with a fully flushed


out project that's you know able to


launch and you know start collecting


users. idea is that you guys have a PC


like a similar to like an ADP but ADP


might even be I think too high to aim


but something that essentially works


that um you can demonstrate to us even


if it's by you know um like I don't know


like like Jen mentioned like spaghetti


you know um even if it's like that


that's fine like that's that's


essentially the expectation but


essentially we're looking at something


that you guys can present that you can


really tell a story to build around a


narrative or on your around your


project.


Yeah. Um


um yeah, it's like uh like I said, if


you think you can boost your score by


starting a team, then by all means join


that team. That is uh that's one way to


to make sure that you're ticking all the


boxes in.


Yeah. Yeah. Yeah. Was there anything


else? Um I think I think this is all and


then what we're going to do is we we've


sent out already the invites for the


demo day to everyone. Um essentially


what's going to happen is just to you


know lay out the formats as well. After


everyone submits their projects they


will start getting ranked uh from July


7th which is a submission deadline date


and then um all of the judges will


essentially mark the top five projects.


From those top five projects they will


get an opportunity to present in front


of everyone the whole cohort.


Um and so those individuals will each


get like five minutes slots. They will


present their projects and they will get


three minutes Q&A from the judges and


then after this essentially the the


whole thing with you know five teams we


will go into like a 10-minute break


where the judges will convene and they


will discuss which the projects they


would like and they'll collect all the


totaling scores and later on they will


announce the bids directly on the on the


call. Again, this is for the tier one


million projects. The rest of them


essentially that will happen after the


gold. But I'm just essentially laying it


out that you know the top five will have


a chance to be featured directly to you


know some guys from Animoka which is you


know one of the biggest VCs in the space


as well as other um ecosystem partners


and prominent names as well. That's


essentially the the judging um


information and then we will share


information about the uh people who are


actually going to be judges as well


later in the week. Um potentially this


week if not next week we'll definitely


share it just so that you guys


essentially get an idea about you know


who you're going to be presenting your


project as well if you want to tailor to


them.


But I think that's pretty much it that


we want to share today about the the


judging piece that we had in mind. Does


anyone have any questions that's in the


call that you guys would like to ask


about this piece?


Yeah, I heard one. So, we have to create


a UI also, right? A fully pledge. You


don't have to. You don't it's it's not


like a mandatory. It really depends on


your use case and what you have in mind.


But if you want to create it, uh by all


means, you know, you can you can go


ahead and do it to you know,


supplemental points essentially towards


your project. But for example, like we


discussed, right? Some people might be


just focusing on prompting directly


right and even in hackathons some teams


directly build user experiences through


a terminal. So those are all you know


acceptance as well but it really depends


on your project and what you have in


mind. Maybe that that goes to your go to


our second point as well. Yeah we were


going to ask each one of you guys to


share more about your project. So


perhaps you can you can get started. um


we also put you on the spot but may


share more about you know your project


and we can also give feedback about


whether or not the UI is a good idea as


well.


Yeah, I second that. Um let's let's hear


a bit about your project. Yeah. Yeah. Go


ahead. We're listening for you.


And again this is this is very informal


as well. So don't no need to stress. Oh


yeah. So I had this one idea. I mean I


had many ideas but currently I'm working


on this one. So a code life platform uh


you know when this code arrived so


people couldn't just go do the work


offline. So you know um so I I created


this platform where people can come in


and environment and code live to people


can edit in environment. So I'm working


on that.


Okay. So that um it's it's kind of like


an a web- based IDE I guess. uh yeah web


IDE in an you know a live environment


when people when more than two


participants can uh come and edit the


code and write the code and run code and


also I'm working on this feature where I


can add an GitHub repo link and it will


try I mean the model will what it will


do is it will you know uh read the


GitHub repo and implement within the


live platform itself. I'm working on


that currently. Oh, that actually sounds


really interesting. It's a weird


coincidence because someone um someone


was just trying to pitch something


similar to me um a few days back and


what they what they were saying was um


what they wanted to build was basically


like um like cursor but with Discord


integrated in it. So you're you're


coding, but you also have a social


channel and you you talk to people as


you code. But what the their whole


argument for that was um that the kind


of the current coding models, they were


all trained on sort of stack exchange


and and these sites, but now people


don't post the coding problems on stack


exchange. They ask the AI. So there's no


more data being generated about um


containing both the code and the


question and the answer. um which means


that it's going to be really difficult


to train future generations of AI


because there just isn't the human data


there. So this guy was suggesting oh


well we'll make a a kind of Discord


integrated IDE where people code and


they talk about the code and it's free


but in exchange for that you have to


give all your data to you know you're


selling your data to to train future


models. Um which I thought was a really


interesting concept. So, I guess your


your project kind of fits in all that. I


should put you in touch with him so that


you guys can build it out and fundra.


Yeah, sure. Even I had um I I I I can


show you like what I build uh if I'm


allowed. Yeah. Yeah. Go ahead. Yeah. If


if you have a UI, that would be perfect


to look at it.


Just a second. Let me share the screen.


And then yeah, after Rohan essentially


we can just go around the circle.


for anyone I kind of do the same


practice.


Yeah, I'm just sharing my screen just


is my visible.


Yeah. So this is


so this is what I created um code live.


We can join live lobby over here. Here


we have two options. Uh start a new


session or we can also join the session


by putting the new code. We started a


new session.


Yeah, let me just start a new file. Um,


file to be main. Let me put it in


Python.


Create.


Now I also need a second user. So now


let me create an one user in eco.


Oh, let me um give some log details.


Okay. So this is user one. Um this is


user two. If I copy this session and


give it to him over here and ask him to


join,


he will be in the same session as


me.


Let's say suppose this is the uh second


user editing over here and like write


this is user two


this is


and so in main js also we can dig this


room


one


and you can also see you know


participants total over here. So I'm


working on this currently uh chat


section and the GitHub section.


Okay. So my my main question about this


is how is the superior agent framework


um going to be in


Yeah. So behind um in this behind the


back end I uh integrated this computer


agent over here using this open a I mean


open router free API X free tools behind


okay so the agent can like join in the


coding. uh yeah even even I'm thinking


to you know uh join and bot over here


like an agent will be joining over here


I'm just thinking and how will I


implement over implement that using


agent that's my main goal agent will be


the third participant among them and you


know it will help coding


oh nice yeah I like that idea sounds


good yeah yeah that was also my question


as well but I I really like that


especially if you can get the agent to


join as well I Um that would be super


cool. One thing that maybe you can also


think of is right I'm working on that


and also I need a few guidance from you


on like how will how will I have the how


will he think and all


yeah no for sure yeah you can you can


reach out to me on on telegram and I can


help answer it and if not I'll also


connect you with someone on from the


engineering as well but yeah I think


you're on the right path so if you can


essentially implement that as well um


just so it's also visible a little bit


on the front end then that would be


super cool like maybe what you can also


do is right just a as a side idea um you


can give like a special prompt so we


give that the agent can also essentially


collaborate as well similar to what you


do on curs


okay okay got it and so I I have also


wrote this few there will be also this


voice coding and datab assistant which I


also mentioned about and real time


editor and these are I haven't worked on


this but I've just written this for now


we will we can also implement this in


future


Yeah. No, I think I think this is a


great start. Yeah. Let me know if you


need any other help, but I think this is


this is a solid start. Um,


do you have any other comments on this,


Jen? Um,


me. Oh, Jen. Jen. I No, I think it looks


great. I That's all I have to say so


far, but yeah, looks good. Okay, sounds


good. Yeah, in that case, I'm Rah. I


think Thank you again. I'll ask the


other participants also go through


theirs as well just so we also get them


in in time but yeah this is great let me


know if you have any any questions for


me to help assist you okay yeah sure I


will reach out to you in chat sounds


good sounds good all right so next we


have soul we have sir and then we also


have suggestion as well does any of you


guys want to you know also come um and


you know unmute yourself and share about


you know what what stage you guys are at


what you guys are also building you know


just essentially what we just did with


Roan. And it's totally okay if you guys


don't have like a UI or anything like


that.


I'm going to have to do it um just like


in school and and pick someone


arbitrarily, but I don't like doing that


either. So, I'm hoping that someone will


unmute, but um who who wants to go


first? I guess maybe we should do in an


alphabetical order. Like, pick one of


them. What do you think, Jen? Oh, yeah.


Yeah. No, that's that's fair.


Alphabetical order. But, um do we have


the I can't see. It's like all note


takers at this point. So, um I can't see


who they're actual human. Look, I'll


I'll ping the humans again.


Hello.


I'm here. Soul is here. Hey. Yeah.


Sorry. Uh my


internet I'm in the field. So the


internet is still bad. But I will try to


explain what I do in my agent.


Yeah, I'm now


make a social media agent. Uh maybe I


reach uh Amber in uh Telegram about my


image credit is done but maybe still


about the APA key. So maybe I can share


about the uh result. Maybe you can


correct the how to make a free image.


But I see uh another uh a key free that


can create uh 10 uh posting for uh media


social but only for 10 uh post uh a


month that is a free from uh another


API. Maybe I can uh show you my agent.


Yeah, for sure. Yeah, I from what I


remember you you mentioned about right


generating post essentially and like


images and stuff like that for social


media right with the agent. Yeah. Yeah.


That uh that is uh my uh Yeah, for sure.


Yeah. Feel free to you know share your


screen and kind of walk us through it.


Okay. Okay. Great. Uh,


I think


you can see my screen. Uh Amy. Yeah,


which is here.


Yeah, this is my uh


agent uh running but maybe


use uh not use uh docker but this is


error when we I try to get uh image but


for the text is uh done like this I make


in bas Indonesia for the content but for


the create an error I use daily but I


want to integrate with g mini uh imagine


but I face the error like this. You can


see it Amy. Oh yeah, I got


Yeah, this is my text is done. But when


I create a image that some facing this


but I tried ask about G& that is about


the API key like that. Oh, so it's an


issue with the image API.


Yeah. Yeah. Yeah. Like that. Okay. Yeah.


We we've encountered that a lot as well.


the sort of the the free image services


uh aren't good and the good image


services are free. Um


I think there's there's a few kind of


what so there's no official midJourney


API but there's a few people who are


kind of offering


their own um home brew version which I


kind of literally would um


I mean the the other thing is if if you


are on GCB um


yeah GCB should give you Gemini um which


is they have image


It's It's pretty decent. Yeah.


Yeah. But uh I will try another APK that


is uh free. But I will make uh do it


first then uh I can uh after I get the


post maybe I can share it again with


Emir and you doctor. Thank you. Yeah.


Yeah. I mean in internally what we


actually do is um we and if you really


want to go to the extremes you can


actually do this. We we run our own um


local stable diffusion models um oh oh


no it no longer stable diffusion sorry


it's flux models um for image generation


and use those um a lot of the time uh


just because it's it's kind of more


reliable than having an API but that and


if if you are on GCP it is actually


possible to do that it's it's not too


computer heavy but um yeah it's it's


another chore it's it makes things it


takes longer in the in the immediate


term. So yeah. Yeah. Okay. I see that.


Maybe I can try another uh p for the


create image and maybe the next level is


about the video uh posting that. Yeah, I


mean the video stuff we we've tried that


with with cling. I don't know if cling


has an API but cling cling does great


videos. And um the other one is is VO of


course, but you if you want to have VO


um Google VO videos, I think you need to


apply for access to to both two and


three. Whether you want to use V2, which


is cheaper, or V3, which is more


expensive. You have to apply in advance


and get it um get it validated. You


can't just, you know, pay your money and


start using.


Yeah. Okay. Okay. Actually has the API.


So maybe you could look at that as well.


But yeah, let me know and keep me posted


as well. I I just checked it. they do


have it. Um, and maybe, you know, from


that might be beneficial as well. But


even even then, if if you do the video


stuff, maybe you can just have like a um


like a small like a dashboard like


system where you can just like flush out


the the content that it prepares. That


might be nice as well. But yeah, keep me


posted. I think I think that's a good


start on how it goes and I'll be more


than happy to help you as well. Okay.


Thank Thank you for your attention.


Yep. No, no worries.


Now we have Austin and Shikant. Does any


of you guys want to go next um in


sharing your projects where you guys at


and what you guys have in mind for a


feedback?


Yeah, I want to share my uh screen.


So hope are you seeing my screen?


Yeah, wait and see. Yeah, so I was


trying to develop a co-pilot. Uh so so I


just wanted to build a copilot. So this


is the example that I have just run now.


So it just it's giving the prime number


from 1 to 100. I want to extend the


functionality of this and create a UI


also. So


and also it if the programmer is stuck


it probably gives suggestions and uh


probably you know ask the agent and


probably guide you there.


So,


oh, so in in this case the the goal of


the agent would be to make coding


suggestions that


yeah yeah yeah


and also I have not created the UI. Uh I


probably I'll create the UI and make it


better.


So till now I'm working on the terminal.


Okay. Um


yeah any suggestions or any any I mean


the I mean I'm going in the right


direction or you want to uh any guidance


that you want to give it to me so I can


go on. Yeah I think for the for the


purpose of judging you're going to have


to find a way to um make sure that yours


and Rohan's are are distinct.


Uh yeah


concepts are pretty close to one


another. So yeah, it's it's going to be


I guess it's going to come down to the


front end um or the business case


possibly. Yeah. Uh yeah, it probably uh


we can do it. Uh see he's already has


the business model where he's trying to


collaborate with the users. Mine will be


probably to integrate with any IDE. So


it already existed in the market. So


probably I will pitch it in this way. So


where I can probably uh integrate with


any current IDE and probably from there


on I can uh improve on it.


Uh because


uh


[Music]


Oh, sorry. It's it's cutting. Uh air.


Can you hear I Yeah, it's also cutting


off on my end as well.


Can you can you hear us? You could maybe


you could stop presenting. Um it might


be affecting your internet.


Yeah. So that's what uh I


Yeah, now we can hear you. Now


essentially what I was also going to add


on to Jen's point was I think it's a


good start. What I what it would also be


nice is also in Rowan's case, right? If


you do have the front end or if you even


have like some sort of back end, what


would be nice to show is how does


actually the superior agents also come


into play, right? Doing like almost like


a before after as well to show how it's


improving so that it's it's clear. Keep


in mind that you guys' job will be a bit


tricky, right? Because the the judges,


they won't be super technical. they will


be mostly


um you know BD people like you know


business you know um relations um


representative that you can think of. So


you essentially have to find a way to


make your case against them without


making them feel too confused. Um but I


think I think you have a good start. Um


you you also shared that with me as


well. It's good to see that you managed


to integrate with the repo. What I would


suggest is yeah like definitely have


like an UI and show maybe you know even


like a chain of thoughts like how is


exactly integrating with the with the


Asian framework just so it's it's clear


to see that. Yeah. Yeah. I'll work on it


and probably update you on Yeah.


Perfect. Yeah. Thank you for coming up


as well. Uh next we have Surash and


Augustine. Does one of you guys go want


to go next?


Hello. Oh yeah, we can hear you sir.


Actually I am uh preparing AI power DSA


coach.


So basically means uh I can show


implementation.


Yeah and I know most of the projects. So


when I hear them I I made for Jenny


might be nice as well. So from what I


remember you were building a DSA coach


on a platform that uses like agents to


um help with code execution and to share


to improve their skills like similar to


beat code, right?


Yes sir. But uh with AI integration


usually code don't have AI integration.


So I have built different agent uh such


as uh mentor agent. So mentor agent uh


will uh basically means uh we will chat


with mentor agent and uh uh if our


approach is uh good enough to go then


mentor agent will guide us to the coding


section. Uh then in coding section we


will have the code agent. Uh then uh we


can uh chat with that code agent al also


and uh it will help us to create the


code and after that uh lastly we have


evaluation agent uh which is used to


evaluate our code our space and time


complexities.


So uh basically what uh usually happens


is that uh when we use platforms like


lead code uh it is uh initially


overwhelming uh for the beginners means


beginner uh it is difficult for beginner


to solve DSA and uh in most of the tech


placement DSA is compulsory means uh


usually they ask DSA in our placement uh


preparation process. Uh so uh one minute


I can sh show is it visible? Yep we can


see it. Uh sir so I am having different


agents uh and uh mentor agent, code


agent,


uh evaluation agent and orchestration


agent to manage all uh these three agent


mean managing their flow. uh basically


means initially we will have a mentor


agent then from mentor agent uh it will


take us to the code agent and from code


agent then it will go to the evaluation


agent and uh basically persona agent uh


to manage the tone means if the uh user


is beginner so the tone should be uh the


tone of the agent should be means


beginner friendly if he's intermediate


then tone should be accordingly and if


it he is advance uh advance user uh then


the tone of the agent should be


different.


Um, so I like this I like the concept of


um multi- aent systems which is not


something we really got into in detail


but it's something that I'm I started


out in agent based models so multiple


agents is is where I sir is it visible


sir uh which is uh sir so actually I I


have different problem uh problem


suppose to some reverse the link list


binary search uh binary three suppose uh


we take two some problem so it will be


displayed uh on the left hand side


so uh what's in two some problem


basically our goal is to return the


index of the target variable add add up


the number and return their index


so basically we will traverse to the


array


so suppose at 2 + 7 is 9 means we will


return their index that is 0 and one.


Similarly, here means we will go through


the array. We will find the pairs and we


will return their index. Suppose uh


three is having index zero, two is


having index one and four is having


index two. Uh so our target is six. So 2


+ 4 is actually


it comes to six.


Uh and our goal is to return the index.


Here we lastly have the constraint.


So, so sir actually you get the problem


or not.


[Music]


Hello. Yeah. Yeah, we're listening.


We're listening. Go through it. H means


you are able to understand the problem


or not. I'm asking that mean our goal is


to return the sum of the two numbers. So


that we we understood the program. Yeah,


we we understand it.


So basically we can select language from


here.


So let's go with Python and uh now we


are in mentoring section.


So here it will show like mentoring.


Suppose I I say I am unable to imagine


even a single approach means I am be I


am not able to understand any approach


how to solve this problem and when I sub


submit my approach. So my mentor agent


is


ask so they will respond that uh it's


completely uh okay to feel stuck at the


beginning


and so it basically the agent will tell


me about the basic approach. The simple


approach is to consider the every


possible pair of the number in the input


array and check if their sum is equal to


target. This is the basic brute force


approach.


So,


so basically means if until our approach


is not satisfied, it will not guide us


to the coding system. Suppose more


suppose uh can


use for loops


then uh uh means uh for loop is that


satisfying our uh need. So it will guide


us to the coding section. Uh and uh here


the user is agent has find that user is


beginner. Actually I am working with the


agent because flow is not yet properly


set.


Uh means it should be more mean it


should give more accurate prompt that


you should use two for loops and add two


numbers.


And also here I am having the uh on the


hint agent will generate the hint for


the problem.


And and if we are using um more hints uh


then basically we are beginners.


So suppose and our tone is also set. So


oh this this is neat. This is something


that we've been working on internally


for a while as well, trying to get um


get the chatbot to do an analysis of the


user and work out how how much a user


knows about the subject or or how how


smart they are. So yeah, that's that's


pretty cool.


I also like it as well.


So suppose user is beginner so the tone


will be different. Great start. every


expert was beginner first. So this so


this is at here means uh we will if he


is beginner first line and last line


will be this means every uh user was


beginner first and this intermediate


portion will be generated by my chat


water uh Gemini API key that I have


used.


No, I think yeah s I think this is a


this is a great start that you you have


made especially Jen this pretty much


covers everything that I I've shared on


the multi- aent orchestration session


meeting and um it's it's a good PC what


I would suggest maybe what you can also


do is right now when you swap from the


like the you like the design like the


first stage to coding stage it the


screen kind of change immediately right


in there maybe you might want to add


like a better flow that shows like hey


like now that you you completed the the


critical thinking approach now that


you're ready to code or something like


that like maybe having that more dynamic


might be able to help just on the


presentation side but yeah I think it's


a good start uh yes sir because uh uh it


is actually directly redirectly um uh


redirecting so basically


uh means if approach is brute force or


if it is brute force so it should uh


redirect to the coding section or if it


is intermediate approach or more optimal


approach then it should redirect. So


suppose I submit the approach uh it have


redirected to the coding section. So


here I can actually.


So I have copy pasted the code. So when


I say run


when I say run the test


uh the coding agent will uh analyze my


code and uh means it will give the


output that is great job your solution


over overall good looks your logic is


correct


uh and here also I I have a chatting


option so I can uh chat with it


approach.


Yes. So uh code agent is uh telling


about more optimal approach means our


goal is to not directly give solution to


the user. So basically the stepby-step


solution will be given means uh at the


end user only have to code but


uh and lastly we have evaluation agent.


So our code will get evaluate here. So


as we have chatted a lot and we have


used the end so our uh means out of 10


we will get seven mark and coding code


quality is good. So we are still working


on it sir and uh I also have the uh one


friend Ganesh so he's not currently uh


joining so I'm building with him.


Oh nice.


So yeah um yeah groups always welcome.


So yeah thanks for this looks good. Um


we still have one more participant right


uh to bring in I think so there is one


more part I'm trying to find him. I


think he might actually dropped off. I'm


unable to see him. But yeah, I think um


I think this was yeah, this was a great


experience. Thanks for sharing. Again,


if let me know if you have any questions


as well. But I think you're off to a


good start especially given that you


guys will also have two more weeks to


essentially build as well.


Sir, actually the means our tone is not


correctly set for the agent. So uh


the redirecting will be more in our


control means uh it will not directly


redirect to the coding section.


So mentor agent will not redirect to the


code section and for more for managing


the flow of all uh these three agent we


are using orchestration agent.


So flow is like coding uh mentor to code


port to evaluation agent.


Okay. Okay, that makes sense. There any


suggestions? Uh


you're making good progress. I would


just say carry on. Um yeah.


Yeah, I would I would also agree. Yeah.


But I also do want to ask to you know


everyone else and yourself as well. If


does anyone have any other questions you


know outside of this you know about the


the judging or the stuff this week I


also do want to add that you know this


week we will have a session with one of


our partners as well so the goal there


will be to essentially tell you guys


more about the you know the AI agent


space especially the decentralized AI


agent space what's happening what's some


of the bigger projects are also working


on and some of the portraits that you


guys might also have uh within those


ecosystems as well so they will be


outlining But yeah, I do want to ask


does anyone have any questions about uh


anything that you know we we kind of


covered. We have about five more minutes


to go in the call. So I want to make


sure that you know we're able to answer


it to you guys.


Sure. After this hackathon uh will be


will there be any internship


opportunity?


Um yeah we're we're sort of definitely


open to that I think after the hackathon


finishes. So um yeah I would say just


just stay in touch and you know you have


our contacts so uh yeah let us know.


Yeah. No I also agree like if especially


if you do end up doing a good project


right you're active within the


throughout the program. Uh what we're


essentially going to do is moving


forward whenever we do have exclusive


hiring opportunity we will make sure to


share with you guys especially the top


candidates. So um I would take you know


push definitely throughout the program


whether if you want to make your project


a success or keep continuing and maybe


potentially even joining on board. Um


those are all essentially going to be


you know dependent on how much activity


you are and what's happening but we'll


make sure to share with you again. You


can always reach out as well. Yeah I


agree with that. Okay so I guess and


this video is going to be um it's going


to be available by the website. Yep. I


will upload it right after. So um if


there's no other questions we can


essentially end off the call and um I'll


share the resource with um others as


well so they can kind of see you know


what we discuss in the meeting and get


an overview as well. Great. Thank you


very much. And I think for for people


who missed this um we're going to do a


quick catch up session at 11 tonight


Singapore time. Yeah. Okay. Great. So


yeah, I think that's everything. Thank


you very much. Can't wait to see what


everyone else is building. So yeah,


let's go.


See everyone. Bye. Yes. See you. Bye.


Thank you.



--------------------------------------
MCP Basics
Week 3 (June 23-27)
Understanding Model Context Protocol Fundamentals:https://www.youtube.com/watch?v=a9k4ippwalw
An Introduction to MCP
Hi everyone, my name is Inger and


welcome to the model context protocol


basics. In this tutorial, we'll cover


various different topics related to


MCPS.


So let's get started.


First, I'd like to dive into the


introduction of MCP.


So when you hear the term MCP, it stands


for model context protocol. This is not


about how you control systems or


cryptography those that share acronomy


but are unrelated here. Instead, MCP in


our context is newly introduced open


standard that aims to make much easier


for AI models like large large language


models to connect with external


resources.


A great analogy from entropotic is not


the AI companies behind actually MCP is


that MCP is like a USBC port for AI.


Just as USBC stands is a standard plug


that fits into many devices and


accessories. MCP provides a standardized


way for AI agents to interface with many


different tools and data sources.


In simple terms, MCP defines how an


agent can ask for information actions


from other systems. For example, fetch


the latest sales data from a database or


accesses documents from Google Drive in


a consistent secure manner. It's an open


protocol meaning that it's meant for


anyone to be implementing and use


promoting interpability for various AI


and tool providers which can support it.


And we will dive deeper into how it


works, why it's useful, but keep in mind


that this is a core idea MCP is giving


about giving our AI agents a universal


connector to hook into software and data


ecosystems they need to work with.


So you might wonder, can't we already


connect AI models to tools? We can, but


MCP addresses key key pain points. One


big issue has been that AI models have a


limited memory of conversation which is


a context window and they don't actually


have access to fresh external data.


Without something like MCP, if you want


a model to use as a new data source, say


your company's knowledge base, you would


have to perform a custom integration.


Basically, write a bunch of code or use


a specific library and feed the data


into the prompt. This process often


bespoke and doesn't really scale well


into many sources. According to


entropotic, even the best models have


been constrained by their isolation from


data and trapped behind information


silos requiring custom work for each new


data source to essentially integrate.


MCP matters because it's it standardizes


the disconnection. Think about how in


the early days if you had different


charges for every device, it was a


headache. USB, USBC


um solve that by giving a common


interface for all. Similarly, MCP means


if a tool, for example, a database or an


email service speaks MCP, any AI agent


that also speaks this can immediately


talk to that tool. It saves developers


time. No more reinventing the wheel for


each integration. It also leads to a


better AI performance as well. So when


an AI can pull in exact data that it


needs say for example the latest weather


reports or specific documents at cury


time it its reprocess will be more


accurate and context aware


lastly MCP emphasizes security and


governance as well since it's a


structured protocol companies can have a


dedicated MCP server that acts as a


control gateway to their data


essentially what it means is that they


can monitor what data is requested and


even if it requires authentication or


permissions. Overall, MCP matters


because it's a big step towards making


AI agents truly integrated into real


world systems in consistent, safe and


efficient way. So, how AI agents use


tools today premcp before this tooling


came along developers have been


inventing various strategies to enable


tools with LLM based agents. One


foundational approach is the react


pattern short for reasoning and acting.


In react AI model is prompted to not


just answer directly but to think step


by step and interle actions with


thoughts. For example, an agent trying


to answer who is the president of


France? By reason I should look this up


and that's the reasoning and then


perform an action search


president of France and result comes


back as Emanuel Meccan. Then the agent


concludes the answer. And frameworks


like lang chain build on this by


providing a convenient way to set up


tools. In lench chain, you can define a


set of tools with metadata. So each tool


can have its name, a description of when


you use it and how to call it. And then


the large language model is given a


prompt that lists these tools and


formats to use them. Modern LLMs even


support function calling which lang


chain also leverages. the model um can


output a JSON calling a function and a


framework executes it then feeds it back


into the result of the model. Semantic


kernel which is also developed by


Microsoft introduces the concept of AI


skills and planners. It essentially can


take a user's request and use a planner


algorithm with the help of an LLM to


decide which sequence of skill functions


to execute to fulfill that request. For


instance, if you ask an eskebased agent


um to which is a semantic kernel based


agent to uh schedule a team meeting for


next week and email everyone. The


planner might choose find a common free


time function and then send and send


email function to its skill library.


So DSPI is also another approach. It


stands for declarative structured Python


and it's built by Stanford engineers and


researchers. Instead of writing long


prompts, you can write Python code where


you declare tools and their effects and


the framework ensures the LLM uses up


correctly. For example, you might


declare a tool for web search and a


schema for the expected answer. The spy


will handle orchestrating the LLM to use


a tool and produce a valid answer. All


these tools different as they are


address the same core need giving AI


agents the ability to use external tools


and data. They each one of them have the


pros and cons. LC chain is relatively


straightforward but can be tricky to


manage. Prompt tokens. Semantic kernel


provides powerful planning might be


complex to fine-tune. DSPY reduces the


prompt brittleleness by using code but


developers need to learn its


abstractions.


understanding these sets up to


appreciate how MCP can unify and


simplify abstraction of tool


integrations.


So agents and external resources what


can they actually access? Let's look at


the kinds of external sources and tools


that AI agent can use. One big category


is knowledge bases and databases. Many


agent systems incorporate a vector


database that contains embeddings of


documents or pest dialogues. This allows


the agent to do a semantic search for


the relevant information when needed.


Kind of like an agent's long-term


memory. For example, an agent might have


a tool search dog query that looks up to


your company's internal Vicki for


answers. Another category is the web and


APIs. Agents often have a browser tool


to read web pages or a way to call


external APIs. This give them access to


real-time data that wasn't initially in


their trained knowledge. For instance,


using a weather API to get today's


weather in a specific city or browsing


websites news for the latest updates. In


fact, in one of the cases with Autogen,


which we discussed in the previous um


tutorial, an agent could fetch real-time


stock data via an API before making a


summary. Files and repositories are also


accessible with the proper integration.


Agent could be allowed to read PDF files


or look at look at a code repository.


This is useful for tasks like analyzing


large text or debugging code where an


agent needs to pull from actual file


content. Then we have general tools or


functions. These can be anything. A


calculator tool to do precise


arithmetic, a translator tool to convert


text between languages, an email


function to automate communications,


etc.


Each such tool extends what the agent


can do beyond just generating a text.


For example, if an agent needs to do a


verify a calculation, a calling a


calculator tool ensures accuracy rather


than relying entirely on the LLM's often


spotty math. Finally, memory stores


deserve mention. While not external in


the sense of an independent app, agents


sometimes use external storage to keep


record of what happens. Some frameworks


will write important points to a file or


database. So if the agent needs to


recall something from an earlier


conversation, it can directly fetch it.


And this isn't exactly true learning,


the model's weights aren't changing, but


it's a way to simulate long-term memory.


All these accesses are typically enabled


via specific tools or connectors coded


in agents framework. For instance, lang


chains toolkit has SQL database tools,


web scraping tools, etc. And others have


similar plugins. The key point is an AI


agent is only useful as the tools and


the data they can leverage. Providing


the right external access can


dramatically change an agent's


capabilities, which is why exactly


standards like MCP are emerging to


streamline this access.


While the current methods allow agents


to use tools, there's still several


limitations across this and how it's


done. Firstly, the ecosystem is highly


fragmented. If I'm using line chain, I


set up tools in one format. If I switch


to a different system and want to


integrate a new service, I might need to


entirely adapt this. There hasn't been


one standard for way to use tools or


advertise, hey, I'm here and AI can use


me. Each integration is custom and


bespoke.


This fragmentation is what MCP is trying


to solve by standardizing it interface.


Another issue is the context window of


dependency. So when an agent gets


information from a tool, the the


information is usually has to be put


back back into the model's prompt or


context for the model to use it. LLMs


have a limit on how much they can how


much text they can juggle at once. If an


agent pulls a lot of data, say like a


contents of a long document, it might


not fit in a prompt or more info you


information you feed in, the more


dilution and confusion it can happen.


This means that agents sometimes still


summarize truncate tools outputs,


potentially losing details.


Additionally, today's agents don't truly


rely and learn from their interactions


with tools. For example, if an agent


calls an API, gets a response, uses it


in that moment, but it doesn't remember


the knowledge for future related


unrelated task unless especially the


program to save it. If you made a


mistake using a tool, they won't


automatically correct the underlying


models approach next time. It's really


up to the developers to catch and fix


that error. So, in that case, reli


reliability is another challenge. The


tools can go wrong. Maybe the API


changes formats or the internet


connection failed. Many agent systems


might not be able to handle that, the


agent could get gibberish or an error


and um not have a logic to recover


entirely. So unless the developer


anticipated this obviously, so it's not


uncommon to see an agent hopelessly


confused because say it a JSON from a


tool but got an error instead. So


ensuring a robust error handling often


means more custom coding and testing


from developers. And lastly, their


security. Right now, if you want to be


safe, we often hardcode limitations. For


example, limit an agent's browsing to


certain domains or have it ask for


certain confirmation before executing


something destructive. The human in the


loop checkpoints are used in sensitive


cases. Without a structure way to


enforce permissions, giving an AI agent


too much freedom like file system access


could be very dangerous. So we need


better mechanisms within this ecosystem


to send box or control agent tool use.


These limitations highlight why simply


giving an agent tool isn't the whole


story. we need better infrastructure


similar to which MCP aims to provide and


new ideas um to overcome these issues.


So now I'd like to discuss a little bit


about how MCP actually works


in practice. So imagine you have an AI


agent that wants to get some data or use


a tool. With MCP, the ver is set up as


servers and clients.


An MCP server is like a gateway to a


particular data source or service. For


example, you might run a MCP server that


provides access to your company's


internal documents. That server knows


how to fish the documents, but it


presents this ability in standardized


MCP format. On the other side, your AI


agent acts as an MCP client. So when it


needs something, it sends a request to


the server in the M MCP defined way.


Because MCP is an open protocol, the


agent doesn't need to know the


nitty-gritty of how the server gets the


data. Just like your computer doesn't


need to know how a USB drive is


internally storing files. It just speaks


the UCB protocol, USB protocol to


request the data. MCP defines a


universal schema and an interface for


various kinds of tools. For instance, an


MCP server might advertise, I have a


resource called calendar, and it has an


action that's called list of events,


which returns upcoming events. The agent


can see the subscription when needed.


Formulate a request like calendar.list


events for date range x to y. Key is


that all of this is done in a consistent


format likely in JSON or similarized siz


structure.


Additionally, the two-way communication


means that agent can also send data


back. For example, log this note in CRM.


The server will do it if allowed and all


interactions can be logged or checked by


the server which adds a layer of safety.


An example, suppose our agent wants to


share information between Slack from a


database. But MCP it could connect to


Slack MCP server and a database MCP


server and it might send a message to


Slack and say gets last five messages


from project channel and add it to the


database MCP run query for sales in Q1.


Each server knows how to handle its own


domain and returns a result in a format


the agent can plug in into its own


context. Big AI providers are already


aligning with MCP. An entropotics


Claudia has abilities to work with MTP


servers even provided


sampled server things like Google Drive,


GitHub, etc. OpenAI's tools function and


functioning calling approach are


actually conceptually similar. OpenAI


agents SDK indicates um support for MCP


as well. This means that even if you're


using those AI models, they can be


guided to produce the right kind of MCP


requests when appropriate.


So overall, MCB works by standardizing


the handshake between AI and external


tools. One side offers data in null


format. The other side requests in that


format. So univer uniformity is what


makes it essentially powerful.


Now I'd like to go through a simple


example a case study almost um on with a


MCP with a concrete easy to follow


example essentially. So let's say you


ask an AI agent


how many open support tickets do we have


today? That's a question that likely


requires pulling data from a ticket in


systems. Like let's say you're using an


internal tool or zenesk. Without MCP,


you would have to specifically prepare


the agent and maybe give a tool called


get open tickets that you wrote yourself


to curate the database and in a prompt


you would hinted to use that tool for


such question. This would include and


involve manual setup and bespoke


solution. If your company then switches


a ticketing system, you would have to


update the integration agents


programming and rewrite it entirely.


With MCP, assume you have an MCP server


for your help desk ticketing system. The


server is known to the agent. Maybe it's


listed in the agents available


connections. When the question comes,


the agent thinks this sounds like


something I can get via for example help


desk MCP server and it creates a request


in MCP formats um in a JSON or


structured um call asking for example


help desk get open tickets with


parameter today the beauty is that agent


doesn't need to know how get open ticket


works just just such that function is


advertised by the server the MCP server


receives that runs the actual database


query or API call to the ticketing


system that returns a response and says


count 42. The agent receives this and


knows that the answer is 42 open


tickets. It can then respond to the end


user and say hey we have 42 open tickets


today. The whole interaction was done


through a standardized protocol. If


tomorrow we build another agent even


using a different AI model or framework


as long as it's MCP compatible it could


also curate the help desk server in the


same way. We don't need to build the


integration again. So the example


highlights the benefits. Zero custom


prompt engineering for the specific


query. The agent dynamically found info


with using MCP. Also everything is


structured. The agent didn't


misinterpret the number 42 as something


else because it came in a defined


schema. Overall this makes such


integrations plug-andplay. It MCP


reduces the efforts and er errors in


scenarios where AI needs to fetch and


update information other systems.


So we talked about a lot of things. I


mean we talked about giving agents


access to tools and context. Um but


there's another frontier persistent


memory in continuous learning for


agents.


Right now most agents even those with a


lot of tooling access are somewhat like


um amnesia. like they don't remember


past sessions or improve unless a human


developer fine-tunes them. Think of a


customer support agent that we just


discussed that keeps encountering a


tricky question and each day forgets a


solution it discovered the day before


which is obviously not ideal. We want


agents that learn from experience just


like how people do. One approach is to


build a better persistent system or


memory to our agents. This could be as


simple as logging every question and


answer an outcome and then having an


agent review those logs or as


sophisticated as actually uploading the


model's parameters with new data


even with just external storage with


what we discussed earlier making agent


stateful but memory isn't enough. So


how do they decide what to do with the


memory? This is where almost survival


based evotionally learning comes in. So


as spir agents, we're building a


framework that you can work and later it


embraces it. It treats multiple attempts


or versions of an agent almost like a


population in nature. The agent or


multiple agents instances


tries strategies. Successful ones are


kept perhaps duplicated and the failures


are discarded or tweaked. Over time only


the fittest strategies survive.


So this Darvenian approach means the


agent system is self-improving.


Concretely, a spir agent might self


assess after each task. Did I succeed?


How well? We have done this previously


in a trading competition and you can


actually review the results as well. So


if not, maybe it alters it approach,


tries a different trading strategy or


spawns a different variant to itself to


tackle a problem differently.


So this is quite different from the


static logic that we see in typical


agents today.


But overall, MCP gives agents the sense


and hence to interact with the real


world. Persistent memory gives it the


history and context beyond the single


sessions and evolutionary loop gives it


the form of self-directed improvements.


All of this is geared towards creating


agents that aren't just reactive tools,


but adaptive entities that can survive


in a changing environment, learn new


tricks of their own, reduce the need for


us to constantly update them. And as we


move forwards in this program, keep in


mind how these pieces fit and you will


learn to how you will learn to use MCP


and current integration techniques as a


foundation and um hopefully they will


then explore how frameworks like spear


agents can build on top of this uh with


higher level autonomy and persistence.


So to conclude, we covered a lot of


grounds from multi- aents orchestration


basics to nuts and bolts of integration


with MCPS. The key takeaway about model


contest protocol is um that making lives


of AI developers essentially easier and


agents more powerful by providing a


standardized uh way to connect to AI and


to role of data and actions around it.


Instead of one solution, we get


universal plug for context. But equally


important is to recognize current


limitations and the need for to push


forward beyond just giving agents tools


to actually give them able to learn and


adapt. That's where the concept of


persistent memory and survival based


learning comes in.


So hopefully you learned a lot from the


tutorial today. Um once again spirit


agents framework is one implementation


of working towards this solution and we


hope that you will get there with


exploring hands-on throughout this


program for now. So make sure you


understand the building blocks how to


orchestrate multiple agents for context


how to use tools like MCPS to give your


agents the information and tools they


need. And in the next sessions and we


will explore also the use cases that you


can build around this as well and how we


can apply these principles. We encourage


you to ask questions um you know this is


a very new um cutting edge stuff that


most of you are learning with. So feel


free to ask questions and in discord


engage with the community and we're more


than happy to assist you in your in your


journey during the program here. So


thank you for your time.



------------------------------
Multi Agent
Week 3 (June 23-27)
Multi-agent patterns and orchestration strategies:https://www.youtube.com/watch?v=tixr8ci0vUU
Multi Agent Orchestration
Hi everyone, I'm Emir and today I'm


excited to teach you about multi- aent


orchestration in our summer residency


program.


So first I'd like to talk about


introduction to multi-agent


orchestration.


Multi-agent orchestration involves


multiple autonomous AI agents


cooperating towards a common goal.


Instead of one monolithic AI trying to


do everything, we have a team of agents,


each specializing in a part of a


problem. For example, one agent might


retrieve information, another analyzes


it, and a third writes a summary. This


approach is inspired by real world


teamwork where dividing tasks can make


more complex projects more manageable.


Multi- aent systems are especially


useful in scenarios like an AI research


assistant that splits work among


different agents. One agent finds


resources, another drafts the content


and the last one fact checks. By


orchestrating these agents, we can


tackle complex workflows than a single


agent can handle alone.


Next, I'd like to talk about why use


multiple AI agents.


Using multiple agents allows us to


divide and conquer complex tasks. Each


agent can focus on what it's best. For


instance, one agent might be great at


planning steps while another excels at


executing calculations or searching


databases.


This specialization means each agent


serves a role like a member of a team in


an ecosystem.


Often agents can operate in parallel


which makes a system faster. Think of an


agent gathering data while another one


simultaneously processes the previous


ones. Additionally, agents can


cross-check each other as well. For


example, in a collaborative setup, one


agent plan can be reviewed by another


agents flaws,


leading to a better reasoning through


debate. Overall, multi- aent setups aim


to combine strengths of different AIs


and mitigate individual weaknesses.


Next, let's dive into current frameworks


for multi- aent orchestration as well.


Currently, there are several frameworks


and tools available today for developers


that makes it easy to build multi- aent


systems. Langraph is an open-source


framework that models agent interactions


as a directed graph of steps. It


provides an event-driven nodebased


structure so you can define how


information flows between agents in a


controlled way. This is great for


complex workflows that need


deterministic paths like a decision


tree. Crew AI on the other hand uses a


metaphor of a crew of agents. Each agent


has a defined role like a researcher,


analyst or writer and tasks move in an


assembly line fashion from one agent to


the next. This makes it more intuitive


to design pipelines where each agent


does one stage of the process.


Autogen developed by Microsoft focuses


on agents that communicate by language


natural language conversations.


Agents using Autogen can chat with each


other, ask questions, refine solutions


collaboratively, which is useful for


open-ended tasks. For example, a planner


agent and a solver agent discussing how


to tackle a lead code coding problem.


Lastly, Google's agent kit. This is a


newer library in Typescript which is


goal is to robust agent orchestration.


It provides simple building blocks to


create agents and tools, manage their


states and deploy them reliably. Agent


kit is designed with integration in


mind. So supporting multiple AI models


and APIs and even the newer model


context protocol MCPS which is we're


going to discuss in the next tutorial


for connecting data to these um language


models.


Each of these frameworks offer a


different approach from highly


structured graphs to free flowing


conversations um enabling developers a


choice depending on their use case.


So what are some of the key concepts in


multi- aent systems?


When you're orchestrating a multi- aent


system, certain core concepts can arise.


So first one, agentto agent


communication. It's crucial. Agents


might need to exchange information or is


each ask each other for help. So in uh


in some of the frameworks is this is


done with natural language messages. One


agent speaks to another while others


might use structure formats for clarity.


Task delegation means breaking the


overall job into small chunks of parts.


Assigning those parts to different


agents. Often there's a controller or


manager agent almost like a project or


product manager that knows how to split


the tasks. And role assignment goes


handinhand with delegation. So each


agent is given a specific role or


expertise. For example, in a document


analysis scenario, one agent could be


the reader extracting the tag text.


Another could be analyzer figure out the


insights and the last one could be the


rider generating reports. This way each


agent has a clear scope. So failure


handling also comes in handy within this


process as well because not everything


goes smoothly at all times. So an agent


might might run into an question uh


within this process that he can't answer


or an error using a tool. Good


sophisticated multi- aent orchestration


includes ways to handle these hiccups


such as having an agent ask for


clarification, retrying a step or using


a backup agent or even pausing to get


human input or developers if needed.


Some of the frameworks like autogen


supports human in the loop where human


can step in to correct or guide if the


agents are unsure. Essential goal is to


make the multi- aent system more robust


so that one agent failure doesn't crash


the whole mission.


Next, let's look into collaborative


agents in action um in a use case


scenario. So in this case the use case


is AI research assistant team that is


trying to write a reports on climate


change impacts.


So let's let's focus on this. We have an


team of agents. Agent A which is a


researcher and is tasked with gathering


information. He might use tools like web


search to find relevant articles or


databases of climate data. Next we have


agent B which agent A hands off the raw


information to B as an analyst. B reads


through the data write summaries of


draft reports


highlighting the key trends. So this


could be like changes in crop yields,


weather patterns and any of the shifts


that could be related. Then we have


agency which is the reviewer whose job


is to fact check and polish the draft.


Agency could double check the facts


perhaps by calling a verification tool


or cross-checking specific claims


against a trusted source and make


clarifications. The orchestration here


is essentially sequential. first A then


B then C much like a pipeline but the


agents might also get might also have to


loop back. So if C finds something


unclear it could ask A or B for more


information. This requires communication


channel among them. This example


demonstrates how task delegation when


each agent has a distinct task and agent


communication where passing the work


along asking questions if needed and by


the end how the team produces a


wellressearched verified report which is


ideally higher quality than what one


agent would produce alone.


Now that we talk about a real world


example, let's talk about the


limitations of current approaches.


While multi- aent systems are powerful,


today's solutions have several


limitations.


One issue is static logic. So many of


the orchestrations are smart as the


rules we hardcode. For instance, if you


design a fixed graph of how agents


interact like in langraph, the system


might not cope well with scenarios we


didn't anticipate because it's following


the set path. There's limited


flexibility for agents to change the


workflow themselves. it will require a


developer to update the logic. Another


another major limitation is the lack of


persistent memory or learning. Current


agent frameworks typically treat each


run or conversation as isolated. These


agents don't truly learn from one task


and apply to the next. They're stateless


beyond their immediate context. Meaning,


if you stop and restart them, they only


know what's in their prompt or knowledge


base, but not any new lessons from their


experiences.


This is why we say that lacks of


self-persistence or long-term memory is


very crucial.


Additionally, these agents often still


needs human oversight because AI agents


can make mistakes or might get stuck in


loops of confusion and a human operator,


a developer might need to monitor them,


especially for high stake tasks.


For an example, an agent might


hallucinate a tool result or


misunderstand instruction leading to a


mistake. Without someone to catch that,


multi- aent system can produce wrong


outcomes. Finally, orchestrating many


agents can be complex and expensive.


Essentially, you're running multiple AI


models which can be very costly in terms


of compute usage and system design is a


lot more complex. you have to handle


communication protocols, error cases,


and more. All of these limitations


suggest that while the current


frameworks are great start, there's a


great room for improvements in making


multi-gen systems more adaptive, memory


equipped, and reliable for the next


generation of developers.


So,


as we talked about some of the


limitations, what are some of the new


directions that's happening within this


ecosystem? We're starting to see the


next generation approaches that


addresses some of these limitations. One


direction is making agents more


adaptive, meaning that agent team can


change how they solve a problem based on


what's happening rather than strictly


following a preset flow. For example, if


midway through a task, agents realize


that they need a new tool or an extra


step, adaptive system could accommodate


to this. Another big trend is persistent


agents. The idea is that agents


shouldn't forget everything when a


session ends. They should carry a memory


or even update themselves from what they


learned. Researchers talk about staple


agents that maintains an internal state


or memory across runs. So imagine agents


that after failing a task once, it


remembers that failure and does better


next time. This is a simple form of


learning during deployment, not just


offline training. So in this case a


great example of this is superior agents


framework our solution without going too


deep essentially superior agents takes


inspiration from evolution it uses


Darvenian feedback loop where agents


continuously self-evaluate their


performance and successful behaviors are


kept or replicated while failures are


discarded.


So in essence, the agent population


evolves over time to become more


effective


and it improves autonomously 247 from


learning real world feedback or data.


So this approach combines and emphasizes


self-replication and updation meaning


that an agent can spawn updated version


of itself or adjust its codes or


strategy depending on the use case to


handle new challenges.


The ultimate goal of this investment is


to rely less on human babysitting. If an


agent can notice I'm stuck or I made an


error and then fix itself or call for a


new strategy, it's far more powerful and


safe. These new directions which we will


explore later in the problem in the


program aim to create multi- aent


systems that are more autonomous,


resilient and continuously improving.


So to wrap up,


remember that multi-agent orchestration


is all about combining strengths of


multiple agents. You've seen now how


frameworks like Langraph Autogen allows


us to design an agent team that can


communicate, delegate task and solve


problems collectively.


Each one of these framework has its


niche. Some are more structured, more


deterministic. Others are more flexible


and conversational. We also discussed


the limitations of current approaches.


They often follow fixed logic. They


don't learn by themselves over the long


run and you still have to keep an eye on


them. The exciting part is that the


field is rapidly evolving. New ideas


like persisting self- evvolving agents


in this case superior agents is a hint


at a future where AI agents can improve


themselves much like living organisms


adapt to their environments. In the next


session, we will get more practical


about how these agents can actually


interface with outside worlds. We will


learn about model context protocol MCPS.


Think of it as a standard way for an AI


agent to plug into tools like databases,


live data streams, and understanding MCP


and current tool integration methods


will set the stage for all of you to


later on build and deploy your own


advanced agents.


So in summary, multi- aent systems are


powerful. They're here and they're


getting better. So now let's move on to


how we can make these agents actually do


things in real world through usage and


data access. Thank you for your time.



-------------------------------------
Guest Session with Gaia
Week 3 (June 23-27)
Special guest session featuring insights and perspectives from Gala:https://www.youtube.com/watch?v=tixr8ci0vUU
Multi Agent Orchestration
Hi everyone, I'm Emir and today I'm


excited to teach you about multi- aent


orchestration in our summer residency


program.


So first I'd like to talk about


introduction to multi-agent


orchestration.


Multi-agent orchestration involves


multiple autonomous AI agents


cooperating towards a common goal.


Instead of one monolithic AI trying to


do everything, we have a team of agents,


each specializing in a part of a


problem. For example, one agent might


retrieve information, another analyzes


it, and a third writes a summary. This


approach is inspired by real world


teamwork where dividing tasks can make


more complex projects more manageable.


Multi- aent systems are especially


useful in scenarios like an AI research


assistant that splits work among


different agents. One agent finds


resources, another drafts the content


and the last one fact checks. By


orchestrating these agents, we can


tackle complex workflows than a single


agent can handle alone.


Next, I'd like to talk about why use


multiple AI agents.


Using multiple agents allows us to


divide and conquer complex tasks. Each


agent can focus on what it's best. For


instance, one agent might be great at


planning steps while another excels at


executing calculations or searching


databases.


This specialization means each agent


serves a role like a member of a team in


an ecosystem.


Often agents can operate in parallel


which makes a system faster. Think of an


agent gathering data while another one


simultaneously processes the previous


ones. Additionally, agents can


cross-check each other as well. For


example, in a collaborative setup, one


agent plan can be reviewed by another


agents flaws,


leading to a better reasoning through


debate. Overall, multi- aent setups aim


to combine strengths of different AIs


and mitigate individual weaknesses.


Next, let's dive into current frameworks


for multi- aent orchestration as well.


Currently, there are several frameworks


and tools available today for developers


that makes it easy to build multi- aent


systems. Langraph is an open-source


framework that models agent interactions


as a directed graph of steps. It


provides an event-driven nodebased


structure so you can define how


information flows between agents in a


controlled way. This is great for


complex workflows that need


deterministic paths like a decision


tree. Crew AI on the other hand uses a


metaphor of a crew of agents. Each agent


has a defined role like a researcher,


analyst or writer and tasks move in an


assembly line fashion from one agent to


the next. This makes it more intuitive


to design pipelines where each agent


does one stage of the process.


Autogen developed by Microsoft focuses


on agents that communicate by language


natural language conversations.


Agents using Autogen can chat with each


other, ask questions, refine solutions


collaboratively, which is useful for


open-ended tasks. For example, a planner


agent and a solver agent discussing how


to tackle a lead code coding problem.


Lastly, Google's agent kit. This is a


newer library in Typescript which is


goal is to robust agent orchestration.


It provides simple building blocks to


create agents and tools, manage their


states and deploy them reliably. Agent


kit is designed with integration in


mind. So supporting multiple AI models


and APIs and even the newer model


context protocol MCPS which is we're


going to discuss in the next tutorial


for connecting data to these um language


models.


Each of these frameworks offer a


different approach from highly


structured graphs to free flowing


conversations um enabling developers a


choice depending on their use case.


So what are some of the key concepts in


multi- aent systems?


When you're orchestrating a multi- aent


system, certain core concepts can arise.


So first one, agentto agent


communication. It's crucial. Agents


might need to exchange information or is


each ask each other for help. So in uh


in some of the frameworks is this is


done with natural language messages. One


agent speaks to another while others


might use structure formats for clarity.


Task delegation means breaking the


overall job into small chunks of parts.


Assigning those parts to different


agents. Often there's a controller or


manager agent almost like a project or


product manager that knows how to split


the tasks. And role assignment goes


handinhand with delegation. So each


agent is given a specific role or


expertise. For example, in a document


analysis scenario, one agent could be


the reader extracting the tag text.


Another could be analyzer figure out the


insights and the last one could be the


rider generating reports. This way each


agent has a clear scope. So failure


handling also comes in handy within this


process as well because not everything


goes smoothly at all times. So an agent


might might run into an question uh


within this process that he can't answer


or an error using a tool. Good


sophisticated multi- aent orchestration


includes ways to handle these hiccups


such as having an agent ask for


clarification, retrying a step or using


a backup agent or even pausing to get


human input or developers if needed.


Some of the frameworks like autogen


supports human in the loop where human


can step in to correct or guide if the


agents are unsure. Essential goal is to


make the multi- aent system more robust


so that one agent failure doesn't crash


the whole mission.


Next, let's look into collaborative


agents in action um in a use case


scenario. So in this case the use case


is AI research assistant team that is


trying to write a reports on climate


change impacts.


So let's let's focus on this. We have an


team of agents. Agent A which is a


researcher and is tasked with gathering


information. He might use tools like web


search to find relevant articles or


databases of climate data. Next we have


agent B which agent A hands off the raw


information to B as an analyst. B reads


through the data write summaries of


draft reports


highlighting the key trends. So this


could be like changes in crop yields,


weather patterns and any of the shifts


that could be related. Then we have


agency which is the reviewer whose job


is to fact check and polish the draft.


Agency could double check the facts


perhaps by calling a verification tool


or cross-checking specific claims


against a trusted source and make


clarifications. The orchestration here


is essentially sequential. first A then


B then C much like a pipeline but the


agents might also get might also have to


loop back. So if C finds something


unclear it could ask A or B for more


information. This requires communication


channel among them. This example


demonstrates how task delegation when


each agent has a distinct task and agent


communication where passing the work


along asking questions if needed and by


the end how the team produces a


wellressearched verified report which is


ideally higher quality than what one


agent would produce alone.


Now that we talk about a real world


example, let's talk about the


limitations of current approaches.


While multi- aent systems are powerful,


today's solutions have several


limitations.


One issue is static logic. So many of


the orchestrations are smart as the


rules we hardcode. For instance, if you


design a fixed graph of how agents


interact like in langraph, the system


might not cope well with scenarios we


didn't anticipate because it's following


the set path. There's limited


flexibility for agents to change the


workflow themselves. it will require a


developer to update the logic. Another


another major limitation is the lack of


persistent memory or learning. Current


agent frameworks typically treat each


run or conversation as isolated. These


agents don't truly learn from one task


and apply to the next. They're stateless


beyond their immediate context. Meaning,


if you stop and restart them, they only


know what's in their prompt or knowledge


base, but not any new lessons from their


experiences.


This is why we say that lacks of


self-persistence or long-term memory is


very crucial.


Additionally, these agents often still


needs human oversight because AI agents


can make mistakes or might get stuck in


loops of confusion and a human operator,


a developer might need to monitor them,


especially for high stake tasks.


For an example, an agent might


hallucinate a tool result or


misunderstand instruction leading to a


mistake. Without someone to catch that,


multi- aent system can produce wrong


outcomes. Finally, orchestrating many


agents can be complex and expensive.


Essentially, you're running multiple AI


models which can be very costly in terms


of compute usage and system design is a


lot more complex. you have to handle


communication protocols, error cases,


and more. All of these limitations


suggest that while the current


frameworks are great start, there's a


great room for improvements in making


multi-gen systems more adaptive, memory


equipped, and reliable for the next


generation of developers.


So,


as we talked about some of the


limitations, what are some of the new


directions that's happening within this


ecosystem? We're starting to see the


next generation approaches that


addresses some of these limitations. One


direction is making agents more


adaptive, meaning that agent team can


change how they solve a problem based on


what's happening rather than strictly


following a preset flow. For example, if


midway through a task, agents realize


that they need a new tool or an extra


step, adaptive system could accommodate


to this. Another big trend is persistent


agents. The idea is that agents


shouldn't forget everything when a


session ends. They should carry a memory


or even update themselves from what they


learned. Researchers talk about staple


agents that maintains an internal state


or memory across runs. So imagine agents


that after failing a task once, it


remembers that failure and does better


next time. This is a simple form of


learning during deployment, not just


offline training. So in this case a


great example of this is superior agents


framework our solution without going too


deep essentially superior agents takes


inspiration from evolution it uses


Darvenian feedback loop where agents


continuously self-evaluate their


performance and successful behaviors are


kept or replicated while failures are


discarded.


So in essence, the agent population


evolves over time to become more


effective


and it improves autonomously 247 from


learning real world feedback or data.


So this approach combines and emphasizes


self-replication and updation meaning


that an agent can spawn updated version


of itself or adjust its codes or


strategy depending on the use case to


handle new challenges.


The ultimate goal of this investment is


to rely less on human babysitting. If an


agent can notice I'm stuck or I made an


error and then fix itself or call for a


new strategy, it's far more powerful and


safe. These new directions which we will


explore later in the problem in the


program aim to create multi- aent


systems that are more autonomous,


resilient and continuously improving.


So to wrap up,


remember that multi-agent orchestration


is all about combining strengths of


multiple agents. You've seen now how


frameworks like Langraph Autogen allows


us to design an agent team that can


communicate, delegate task and solve


problems collectively.


Each one of these framework has its


niche. Some are more structured, more


deterministic. Others are more flexible


and conversational. We also discussed


the limitations of current approaches.


They often follow fixed logic. They


don't learn by themselves over the long


run and you still have to keep an eye on


them. The exciting part is that the


field is rapidly evolving. New ideas


like persisting self- evvolving agents


in this case superior agents is a hint


at a future where AI agents can improve


themselves much like living organisms


adapt to their environments. In the next


session, we will get more practical


about how these agents can actually


interface with outside worlds. We will


learn about model context protocol MCPS.


Think of it as a standard way for an AI


agent to plug into tools like databases,


live data streams, and understanding MCP


and current tool integration methods


will set the stage for all of you to


later on build and deploy your own


advanced agents.


So in summary, multi- aent systems are


powerful. They're here and they're


getting better. So now let's move on to


how we can make these agents actually do


things in real world through usage and


data access. Thank you for your time.



-------------------------------------
Week 4 Judging Deep Dive + OSA
Week 4 (June 30-July 4)
In-depth exploration of judging criteria with comprehensive Q&A session:https://www.youtube.com/watch?v=KwkOaoUmBps
Agir Labs Summer Residency - Week 4
Perfect.


I'll screen share.


Right. Could you guys see my screen?


Yes. Yep. Great. Yeah. So once again and


welcome everyone for joining the week


four of the reoccurring call. If you are


watching the recording um today we're


going to go through basic overview of


the judging information. I will reveal


our judges go through about them. Um as


well we'll discuss more about how your


projects will be marked and some of the


logistics as well. And at the end we'll


also have some time to answer some of


your questions. If you have any


questions throughout the you know the


presentation feel free to unmute as


well. Jen, I also noticed that you're


also here. Feel free to say hi.


Hey. Yeah. Sorry about the delay. I had


trouble with my setup, but uh it's


working now. I cuz because I do so many


spaces. I got like a proquality webcam


and a mic and everything. And uh and


sort of nine times out of 10, they don't


connect to each other and they don't


connect to the PC. So, it's it's made my


life a lot worse. But yeah, nice to be


here finally.


Yeah. Nice. Sounds good. Perfect. Yep.


So, we'll reveal our judges. Uh, we have


Julian and Jen joining us from Kiper.


So, Jul Jen, you guys um know her so far


um throughout the program. She's our


chief AI officer. We have Julian as


well, the CEO of Kip Protocol. We have


Jonah um joining from Open Campus. So,


Open Campus is a close initiative that


Kip has collaborated with in the past.


Um I believe Jonah has um excessive


background within the space as well. uh


feel free to share if you like to Jen.


Um and yeah, so Jo Jonah is one of our


partners. He he is with so he's


basically in charge of the open campus


uh projects with OCU and so on. So um


and they also have if anyone is


interested uh an edtech incubator.


So, um I believe that is


uh that comes with a 100,000 USD in or


USDT in funding um if you get accepted


into the incubation program. So, yeah,


that's that's interesting.


Yeah, sounds sounds pretty excited


exciting for I think the some of the


folks that are building in the tech


space. So, definitely keep that in mind.


Um James is joining from Animoka


Ventures. Um so Animoka is one of the


biggest VCs within the landscape. Um I


would say they they have a big very big


portfolio from um you know gaming to


many other initiatives. Um so he will


also be joining and we have also push


joining as well from Spiran. Um Jen if


you like also feel free to include some


background about them as well.


Yeah. Um so Speron they they provide


compute. We've we've actually used their


compute in the past. So it it's there


and it exists.


Um,


so what so they're coming in as a judge


this time because they um next time they


they actually want to be like full-on


participants like Gaia were this time


around and and do training and so they


just didn't have anyone who would be


available within the time. Um, but yeah


uh they they do a lot of compute


provisions. So if you're interested in


in getting some free some free or cheap


compute um to help out with your


projects uh yeah get in touch.


Yep. Sounds great. Yeah. So this is


essentially our judge of live panel will


have um all the judges will essential re


review all the the project submissions


um after the projects are submitted. Um,


so it will be very key for all of you to


for the ones that are present today, but


for the ones that are watching the


recording to also submit their projects


by July 7th, 11:59 p.m. SGT. Um, the


reason why we ask this is, you know, a


lot of the the programs like this


hackathons, sometimes they provide


extensions, but in this case, we are not


going to be able to do that um unless


there's a very key emergency. And the


reason being that is because um on July


9th there will be demo day to all of the


judges that will be in the call and


we'll have to pick the top five ranked


projects before that. So that gives us


you know essentially a day to go through


all the projects discuss them with our


judges um and then invite them to to the


demo day as well. So this is this is


very important that the deadline is


spread and we will also reach out to all


of the the participants as well um you


know 24 hours before the call. So I've


shared a Google form link in the


telegram chat and it's also live in our


website as well. It'll be live after


this along with the recording that you


can go and submit your project. So if


you worked um just yourself, you can


include your name, your details. If you


work with other participants, please


also include their names as well as well


as their telegrams and their emails so


that we have them on file. Um the form


is very basic. it just ask your name,


email, telegram ID, what project you're


building in one sentence, a brief


explanation of your project as well,


like two to three sentences just to get


a bit of idea before watching the demo


video. And then there's obviously the


GitHub link, you know, which our


technical team will review to see, you


know, how much technical implementation


has been done on your project. And um a


video link that you can drop from like


Google Drive, Loom, um YouTube, you


know, whatever platform you prefer. make


sure that link is also accessible to


everyone that has a link um so that we


don't run into last minute issues while


reviewing their project. Again, all of


these are mandatory. Um for some of the


folks that haven't been able to build a


very fully likeed out or like a scaled


up project, again, you can still have


like a very simple demo. You can even


have a presentation, go through your


business idea, your project, and then


have like a one or two minutes going


through the user flow as well. These are


all possible. What's very important is


that right the presentation is very key


for us to really get the first uh


impression with the product that you're


building. So I would say very like put


put very much emphasis on that and make


sure that you guys don't do it last


minute because in a lot of the


hackathons you know the participants


they end up doing their their projects


and video pitches last minute and then


actually it ends up being the project


quality down um even though there's a


lot of technical implementation uh being


done. So um that's essentially the how


the project will be judged. Jen,


anything you would like to add to this?


Um yeah, I would say it I assume there's


there's been a lot of forks of the repo,


but uh just in case um


anyone has been, you know, building


purely locally, if possible, please


upload your projects as a fork of the


current repo rather than as a totally


independent repo on GitHub or whatever


because we obviously we were very keen


to share these and it it just makes it a


lot easier for us to keep track. Um,


actually one thing that I meant to say


and I forgot to add um housekeeping.


Sorry. Can we can we add a um can we add


a a um what do you call it? Uh


oh, I've forgotten the word. Um a box on


the form for uh a field. That's it.


Can we add a field on the form for


Twitter IDs? Um yeah, because Yeah, we


have that as well. Yeah. Yeah, sorry.


Um,


yeah, uh, I was asked for it and I


forgot to bring it up, so that's my bad.


Y, sounds good. Yeah, I'll I'll make


sure that's also there as well. Um, but


yeah, we we'll definitely include it.


Yeah, again, like if you guys have any


questions, let us know. I think barely


everyone is making good progress with


their projects. Um, and they're, you


know, they're going throughout the the


whole process as well. But you if


there's anything that you want to


confirm, if you haven't had a chance to


build out very scaled out in the last


couple of weeks, but you're looking to


flush it out this week, let me know. You


can get in touch with me. I'll make sure


to set some time maybe jump in a call or


I'm just pushing out through Telegram


async as well. There's already a couple


of folks that I'm you know helping


mentoring oneonone. Uh but that's I


would say that's the mainly the the


judging panel as well as the how the


projects will be fleshed out and how the


um the log logistics will be run. Um,


does anyone want to ask any questions


um, you know, that you guys would like


to bring up in here?


Yeah, you guys can ask questions about


the the judging stuff and then um, we


can go limit into the project details as


well if you guys want to ask about that.


Yeah, I would say um a few people did


reach out to me asking about their


projects and I think great um


yeah uh I I will advise as far as I


possibly can on that and I think


creative integrations like Telegram or


like whatever they are very keen on


that. Um,


and also if you need any help from the


developers, um, so there's, uh,


SWE in the chat is is one of the


original devs, so you you can also reach


out to him and ask ask questions as


well.


Uh, oh, can Okay, got a question. Um,


yep. Yep, I could take that. So, yeah.


Yeah, go ahead. Yeah. Essentially,


Adara, what's going to happen is um when


you're submitting your project, they


will ask you to do a five three to five


minute demo of your project and you


explain your use case. So, this can be


like a very brief explanation of the


project that you're solving, the problem


that you're trying to tackle and what


does it actually uh work for and then


you can have a very short demo of your


platform or you know essentially the


framework or solution that you've built


out. So, you can screen share, you can


show this. You don't have to turn on


your camera if you don't want to. that's


not a mandatory uh we we respect that.


So, but essentially that would be the


demo and then we would ask you to


download upload that to YouTube, Loom or


you know Google Drive and then share the


link and submit that within the project


submission and if you are ranked within


the top five candidates we will reach


out to you directly on the DMs and we'll


tell you that you know you've made it to


the top five. will also announce this


before the demo day and then in demo day


there will be a set schedule of who will


present first and you will essentially


present it in front of the judges. The


judges will also do some marking um and


they'll give direct feedback as well. Um


so in that day essentially we will get


to see you know who places first,


second, third, fourth and fifth but more


importantly you'll get to present your


project in front of very key people


within the ecosystem. So that's


essentially it. But even if you don't


make it to the top five, uh I would say


like it's mandatory for everyone to


attend the demo day, right? If you if


you let's say have a very good project


but you don't make it and you're


frustrated and you you choose not to


join, it's not very good because we we


want to ensure that you also get to see


other participants projects as well and


it's one of the requirements to ensure


that you guys receive the slide dates.


Anything that you wanted to add to that,


Jen? Yeah, I I would kind of um say that


this this is the bit the technical


founders always hate, but it's that is


also it's also part of the reason that


it's it's kind of necessary. Um because


like I like I said before, if you have


the best app in the world and no one


knows about it, then it's not the best


app in the world. So yeah, that that's


why it's part of the the thing. and you


you know however you want to present it


you have the same amount of latitude as


if you were you know pitching to a VC or


whatever which you kind of are because


some some of the some of the judges are


VCs so yeah um the goal is to to impress


basically


yep yeah yeah again like like Jenn says


right you might you guys might have the


best technical um capability project


that has built out but essentially if


you can't tell the story about what you


have built and why you built it it


becomes really useless So that's that's


essentially um all about it. But it


doesn't answer your question or doctor.


Feel free to ask um anything more as


well.


Oh yeah. So I had a question. So for now


an working MVP with two agent will be


fine right for demo day.


Sorry what was that? um


like an uh working MVP or Yeah. Yeah.


100%. Um


uh and


you know uh if you if there are bits


that are not complete yet, so you only


have like a a basic front end or you


bits of bits of it that you're planning


to build out later but you haven't built


out then yeah that's it's still fine.


Yeah. Uh I mean the number of times I've


pitched to a VC pretending that a


screenshot was a live website is uh is


not small. So yeah.


Yeah. And and another thing I do want to


highlight is you guys if I know that


some of you guys built out a bunch of


features, right? There's there's very


small features and you you essentially


want to probably highlight all of them,


right? Because you're you built it out.


It's your app. But I think it's very key


that you guys be very selectable about


what you want to demo as well, right? So


what I would suggest is about ideal


workflow in your mind and work that out


to make sure that it fits within that


three to five minute pitch right because


timing will be very key and essentially


if you guys pass that five minute


benchmark we'll have to cut the


presentation short um to give every


everyone else a chance to also present


as well during that demo day.


Yeah. And I think what what I would also


say is um you know uh e even for the


even for the projects whether your


project gets selected for the demo day


or not um I'm still happy to kind of put


you in touch with with resources and and


say you know for what my VC contacts are


worth. They're not they're not the most


spectacular in the industry, but um


yeah, I can try and find try and help


you out and try and you know, if if


you're looking for a job or you're


looking for um funding or you you want


to do something else, just reach out.


Yeah. No, we're definitely there to


we're definitely open to help you guys,


right? Like regardless of again like you


guys make it a demo day or not, like


this is the first time we're offering


this program. So, we're very excited to


keep this close contact with you guys


and see how you guys succeed. whether if


it's like you guys joining a team in the


space, you know, collaborating with with


us or um essentially building out your


own project.


Yeah, thank you. That would be really


greatful.


I mean, it's it's in our interest as


well. The more the more VCs see projects


that are built using superior agents,


the better our stock is. So, yeah.


Does anyone else have any other


questions? Feel free to unmute guys or


type it in the chat.


Yeah. In the meantime. Yeah. Go ahead.


Go ahead. No, I was saying uh no


questions for now, I would think. Okay.


Yeah. What I was going to also mention


was I I reached out to some of you guys


and we actually talked.


Sorry, one second if background sounds.


Usually usually that's me.


Yeah, I'm not sure what's happening.


It's it's 12 a.m. almost in in Canada


and people are decide to um street race


with motorcycles. Well, but um but


essentially what I was referring to was


if if any of you guys also have um you


know your projects deployed on like


universal netifi like any sort of like


hosting that we can also check it out


feel free to share with me. We'll do


another round of features this week uh


for the top projects that essentially


are building within ecosystem that have


shared it with me that are very


interesting for our community members.


So if you I know that some of you have


already shared it. If you haven't feel


free to send it out to me and then I'll


share with our marketing team for them


to you know share more about your


project as well because we did bit of


feature last week for five projects. We


want to do some for the other uh others


as well.


Yeah. Yeah. Yeah. So we don't want to


you know it's not that we're biased in


particular in favor of particular


projects. They're they're mainly the


ones that were you know around and


available. So if you do want to get your


project featured on our Twitter and and


other social media then yeah uh being in


this meeting is a great way to start and


then just reaching out essentially.


Yeah.


Yeah. I totally agree. It's essentially


our way of just sharing with our


community what you guys are being up to


rather than um you know favoring the


projects as as far as you guys can tell


like I'm not even on the judging panel.


So um it's it's essentially the the


judges that will be and not marking the


project.


Um, we just want to be very transparent


and just, you know, help you guys


amplify your projects more.


Yeah, I agree with that.


Any others um that want to ask any other


questions?


Okay. Um, S uh any internship


opportunities available? Um yeah,


potentially uh


get in touch and we can talk about it.


Yeah, I think what's a a really good way


to start with that is essentially to


make sure that you know um depending on


what area you are potentially interested


in interning in you know very put up


very much focus and make sure that your


project can really highlight that as


well because ideally if if you make a


very impressive project you know that


makes our our job or other people's job


um easier to maybe potentially hire you


right so I think that's a that's a very


good start


yeah uh I mean Nor normally when


I I think we already have your GitHub,


right? Um so normally when I'm


recruiting for internships, I I don't


ask for qualifications, but I do ask for


GitHub. So, um, yeah,


uh, I would say right now in terms of


what we're what we're recruiting for is


mainly looking for, um, ML engineers and


MLOps guys, particularly if you have


experience with bare metal stuff and


especially if you have experience with


Tens torrent chips, which barely anyone


has. So, it's it's kind of a rare thing,


but um yeah,


that sounds good. If anyone else doesn't


have any questions, I think we can head


towards um wrapping it up. Yeah. Oh,


yeah. Yeah. I had a question. Uh you


mentioned about like uh before um before


uploading the project, you have to


upload it on GitHub, right?


Oh, yeah. Um so ideally these projects


would be uh a fork of the existing


superior agents repo. So just just fork


the existing repo and then put your own


project in there. Okay.


Perfect. Uh yeah, I I if that's


everything, we uh we're going to be


doing another call tonight. The tonight


might finally be the day I managed to


record successfully.


Last time I think I asked Christine to


do it and she managed to get five


minutes and then it cut out. So um Oh,


Jen, if you would like, I can I can


enable that recording on my side as


well. I can do that for you. Oh, okay.


Oh, yeah. Since since we since we have


this one recording, like I usually


upload the one recording on a weekly


basis, so I think we should be okay.


Okay. Yeah. Yeah. No, and that it's


fine. Yeah, I sort of I think Chris


managed to get five minutes and then I


ended up having to take one outdoors in


the middle of Singapore and I couldn't


record that. So, um yeah. Yeah, I


haven't had a lot of luck with this, but


um yeah, fingers crossed. Yeah, sounds


good. Yeah, once again everyone,


congrats on wrapping up the the week


four. We're very excited to see your


guys' submissions. Um, you know, I think


it's going to be very exciting to be of


building, polishing out your projects


and going from there. So, um, you know,


feel free to reach out to us, me or Jen


directly, um, to get help or any other


resources you guys might need. But yeah,


otherwise uh, we'll we'll talk to you


guys soon.


Yeah, see you guys soon. Bye. See you.


Thank you. Bye.



-----------------------------------














